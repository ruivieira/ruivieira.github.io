<!doctype html><html lang=en-uk>
<head>
<script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script type=module src=/js/deeplinks/deeplinks.js></script>
<link rel=preload href=/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=stylesheet href=/css/kbd.css type=text/css>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<title> Counterfactual Fairness · Rui Vieira</title>
<link rel=canonical href=https://ruivieira.dev/counterfactual-fairness.html>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="all,follow">
<meta name=googlebot content="index,follow,snippet,archive">
<meta property="og:title" content="Counterfactual Fairness">
<meta property="og:description" content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high `FYA`.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ruivieira.dev/counterfactual-fairness.html"><meta property="article:section" content="posts">
<meta property="article:modified_time" content="2022-03-02T21:09:11+00:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Counterfactual Fairness">
<meta name=twitter:description content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high `FYA`.">
<link rel=stylesheet href=https://ruivieira.dev/css/styles.27ac4434a916af345ffe30d3656131e5f7a550e1bc0d3b921397999cd038ce9531bf583bfb5db3d7033827d55c204ab99ee1da47c0b66465620537ad61b1684a.css integrity="sha512-J6xENKkWrzRf/jDTZWEx5felUOG8DTuSE5eZnNA4zpUxv1g7+12z1wM4J9VcIEq5nuHaR8C2ZGViBTetYbFoSg=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]-->
<link rel=icon type=image/png href=https://ruivieira.dev/images/favicon.ico>
</head>
<body class="max-width mx-auto px3 ltr">
<div class="content index py4">
<div id=header-post>
<a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick="$('html, body').animate({scrollTop:0},'fast')" style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu>
<span id=nav>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/map/>All pages</a></li>
<li><a href=/search.html>Search</a></li>
</ul>
</span>
<br>
<span id=actions>
<ul>
<li>
<a class=icon href=https://ruivieira.dev/counterfactual-fairness-in-java.html aria-label=Previous>
<i class="fas fa-chevron-left" aria-hidden=true onmouseover="$('#i-prev').toggle()" onmouseout="$('#i-prev').toggle()"></i>
</a>
</li>
<li>
<a class=icon href=https://ruivieira.dev/correlation-matrix.html aria-label=Next>
<i class="fas fa-chevron-right" aria-hidden=true onmouseover="$('#i-next').toggle()" onmouseout="$('#i-next').toggle()"></i>
</a>
</li>
<li>
<a class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast')" aria-label="Top of Page">
<i class="fas fa-chevron-up" aria-hidden=true onmouseover="$('#i-top').toggle()" onmouseout="$('#i-top').toggle()"></i>
</a>
</li>
<li>
<a class=icon href=# aria-label=Share>
<i class="fas fa-share-alt" aria-hidden=true onmouseover="$('#i-share').toggle()" onmouseout="$('#i-share').toggle()" onclick="return $('#share').toggle(),!1"></i>
</a>
</li>
</ul>
<span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span>
</span>
<br>
<div id=share style=display:none>
<ul>
<li>
<a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label=Facebook>
<i class="fab fa-facebook" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label=Twitter>
<i class="fab fa-twitter" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Linkedin>
<i class="fab fa-linkedin" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label=Pinterest>
<i class="fab fa-pinterest" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label=Email>
<i class="fas fa-envelope" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Pocket>
<i class="fab fa-get-pocket" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=reddit>
<i class="fab fa-reddit" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20%60FYA%60." aria-label=Tumblr>
<i class="fab fa-tumblr" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News">
<i class="fab fa-hacker-news" aria-hidden=true></i>
</a>
</li>
</ul>
</div>
<div id=toc>
<h4>Contents</h4>
<nav id=TableOfContents>
<ul>
<li><a href=#building-counterfactually-fair-models>Building counterfactually fair models</a>
<ul>
<li><a href=#data>Data</a></li>
<li><a href=#pre-processing>Pre-processing</a></li>
<li><a href=#protected-attributes>Protected attributes</a></li>
<li><a href=#training-and-testing-subsets>Training and testing subsets</a></li>
</ul>
</li>
<li><a href=#models>Models</a>
<ul>
<li><a href=#unfair-model>Unfair model</a></li>
<li><a href=#full-model>Full model</a></li>
<li><a href=#fairness-through-unawareness--ftu>Fairness through unawareness (FTU)</a></li>
<li><a href=#latent-variable-model>Latent variable model</a></li>
<li><a href=#additive-error-model>Additive error model</a></li>
<li><a href=#comparison>Comparison</a></li>
</ul>
</li>
<li><a href=#measuring-counterfactual-fairness>Measuring counterfactual fairness</a>
<ul>
<li><a href=#statistical-parity-difference-disparate-impact>Statistical Parity Difference / Disparate Impact</a></li>
<li><a href=#finding-sensitive-features>Finding sensitive features</a></li>
</ul>
</li>
</ul>
</nav>
<h4>Related</h4>
<nav>
<ul>
<li class="header-post toc"><a href=https://ruivieira.dev/counterfactual-fairness-in-java.html>Counterfactual Fairness in Java</a></li>
<li class="header-post toc"><a href=https://ruivieira.dev/explainability.html>Explainability</a></li>
</ul>
</nav>
</div>
</span>
</div>
<article class=post itemscope itemtype=http://schema.org/BlogPosting>
<header>
<h1 class=posttitle itemprop="name headline">
Counterfactual Fairness
</h1>
<div class=meta>
<div class=postdate>
Updated <time datetime="2022-03-02 21:09:11 +0000 GMT" itemprop=datePublished>2022-03-02</time>
<span class=commit-hash>(d95ed60)</span>
</div>
</div>
</header>
<div class=content itemprop=articleBody>
<h2 id=building-counterfactually-fair-models>Building counterfactually fair models</h2>
<h3 id=data>Data</h3>
<p>To evaluate <em>counterfactual fairness</em> we will be using the &ldquo;law school&rdquo; dataset<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p>
<p>The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (<code>LSAT</code>), their grade-point average (<code>GPA</code>) collected prior to law school, and their first year average grade (<code>FYA</code>).
Given this data, a school may wish to predict if an applicant will have a high `FYA`. The school would
also like to make sure these predictions are not biased by an individual’s race and sex.
However, the <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> scores, may be biased due to social factors.</p>
<p>We start by importing the data into a [Pandas]] <code>DataFrame</code>.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>warnings</span>

warnings<span style=font-weight:700>.</span>filterwarnings(<span style=color:#b84>&#34;ignore&#34;</span>)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>pandas</span> <span style=font-weight:700>as</span> <span style=color:#555>pd</span>

df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>read_csv(<span style=color:#b84>&#34;data/law_data.csv&#34;</span>, index_col<span style=font-weight:700>=</span><span style=color:#099>0</span>)
df<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>       race  sex  LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0     White    1  39.0   3.1           GL -0.98      0.782738       1.0
1     White    1  36.0   3.0           GL  0.09      0.735714       1.0
2     White    2  30.0   3.1           MS -0.35      0.670238       1.0
5  Hispanic    2  39.0   2.2           NE  0.58      0.697024       1.0
6     White    1  37.0   3.4           GL -1.26      0.786310       1.0
</code></pre></div><h3 id=pre-processing>Pre-processing</h3>
<p>We now pre-process the data. We start by creating categorical &ldquo;dummy&rdquo; variables according to the <code>race</code> variable.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>get_dummies(df, columns<span style=font-weight:700>=</span>[<span style=color:#b84>&#34;race&#34;</span>], prefix<span style=font-weight:700>=</span><span style=color:#b84>&#34;&#34;</span>, prefix_sep<span style=font-weight:700>=</span><span style=color:#b84>&#34;&#34;</span>)
df<span style=font-weight:700>.</span>iloc[:, : <span style=color:#099>7</span>]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   sex  LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0    1  39.0   3.1           GL -0.98      0.782738       1.0
1    1  36.0   3.0           GL  0.09      0.735714       1.0
2    2  30.0   3.1           MS -0.35      0.670238       1.0
5    2  39.0   2.2           NE  0.58      0.697024       1.0
6    1  37.0   3.4           GL -1.26      0.786310       1.0
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>7</span> :]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   Amerindian  Asian  Black  Hispanic  Mexican  Other  Puertorican  White
0           0      0      0         0        0      0            0      1
1           0      0      0         0        0      0            0      1
2           0      0      0         0        0      0            0      1
5           0      0      0         1        0      0            0      0
6           0      0      0         0        0      0            0      1
</code></pre></div><p>We also want to expand the <code>sex</code> variable into <code>male</code> / <code>female</code> categorical variables and remove the original.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df[<span style=color:#b84>&#34;male&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;sex&#34;</span>]<span style=font-weight:700>.</span>map(<span style=font-weight:700>lambda</span> x: <span style=color:#099>1</span> <span style=font-weight:700>if</span> x <span style=font-weight:700>==</span> <span style=color:#099>2</span> <span style=font-weight:700>else</span> <span style=color:#099>0</span>)
df[<span style=color:#b84>&#34;female&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;sex&#34;</span>]<span style=font-weight:700>.</span>map(<span style=font-weight:700>lambda</span> x: <span style=color:#099>1</span> <span style=font-weight:700>if</span> x <span style=font-weight:700>==</span> <span style=color:#099>1</span> <span style=font-weight:700>else</span> <span style=color:#099>0</span>)
df <span style=font-weight:700>=</span> df<span style=font-weight:700>.</span>drop(axis<span style=font-weight:700>=</span><span style=color:#099>1</span>, columns<span style=font-weight:700>=</span>[<span style=color:#b84>&#34;sex&#34;</span>])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>0</span>:<span style=color:#099>7</span>]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   LSAT  UGPA region_first  ZFYA  sander_index  first_pf  Amerindian
0  39.0   3.1           GL -0.98      0.782738       1.0           0
1  36.0   3.0           GL  0.09      0.735714       1.0           0
2  30.0   3.1           MS -0.35      0.670238       1.0           0
5  39.0   2.2           NE  0.58      0.697024       1.0           0
6  37.0   3.4           GL -1.26      0.786310       1.0           0
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>7</span>:]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   Asian  Black  Hispanic  Mexican  Other  Puertorican  White  male  female
0      0      0         0        0      0            0      1     0       1
1      0      0         0        0      0            0      1     0       1
2      0      0         0        0      0            0      1     1       0
5      0      0         1        0      0            0      0     1       0
6      0      0         0        0      0            0      1     0       1
</code></pre></div><p>We will also convert the entrance exam scores (<code>LSAT</code>) to a discrete variable.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df[<span style=color:#b84>&#34;LSAT&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;LSAT&#34;</span>]<span style=font-weight:700>.</span>astype(<span style=color:#999>int</span>)
df<span style=font-weight:700>.</span>iloc[:, :<span style=color:#099>6</span>]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0    39   3.1           GL -0.98      0.782738       1.0
1    36   3.0           GL  0.09      0.735714       1.0
2    30   3.1           MS -0.35      0.670238       1.0
5    39   2.2           NE  0.58      0.697024       1.0
6    37   3.4           GL -1.26      0.786310       1.0
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>6</span>:]<span style=font-weight:700>.</span>head()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   Amerindian  Asian  Black  Hispanic  Mexican  Other  Puertorican  White  \
0           0      0      0         0        0      0            0      1
1           0      0      0         0        0      0            0      1
2           0      0      0         0        0      0            0      1
5           0      0      0         1        0      0            0      0
6           0      0      0         0        0      0            0      1

   male  female
0     0       1
1     0       1
2     1       0
5     1       0
6     0       1
</code></pre></div><h3 id=protected-attributes>Protected attributes</h3>
<p><em>Counterfactual fairness</em> enforces that a distribution over possible predictions for an individual should
remain unchanged in a world where an individual’s protected attributes \(A\) had been different in a causal sense.
Let&rsquo;s start by defining the <em>protected attributes</em>. Obvious candidates are the different categorical variables for ethnicity (<code>Asian</code>, <code>White</code>, <code>Black</code>, <em>etc</em>) and gender (<code>male</code>, <code>female</code>).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>A <span style=font-weight:700>=</span> [
    <span style=color:#b84>&#34;Amerindian&#34;</span>,
    <span style=color:#b84>&#34;Asian&#34;</span>,
    <span style=color:#b84>&#34;Black&#34;</span>,
    <span style=color:#b84>&#34;Hispanic&#34;</span>,
    <span style=color:#b84>&#34;Mexican&#34;</span>,
    <span style=color:#b84>&#34;Other&#34;</span>,
    <span style=color:#b84>&#34;Puertorican&#34;</span>,
    <span style=color:#b84>&#34;White&#34;</span>,
    <span style=color:#b84>&#34;male&#34;</span>,
    <span style=color:#b84>&#34;female&#34;</span>,
]
</code></pre></div><h3 id=training-and-testing-subsets>Training and testing subsets</h3>
<p>We will now divide the dataset into training and testing subsets.
We will use the same ratio as in <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, that is 20%.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>from</span> <span style=color:#555>sklearn.model_selection</span> <span style=font-weight:700>import</span> train_test_split

df_train, df_test <span style=font-weight:700>=</span> train_test_split(df, random_state<span style=font-weight:700>=</span><span style=color:#099>23</span>, test_size<span style=font-weight:700>=</span><span style=color:#099>0.2</span>);
</code></pre></div><h2 id=models>Models</h2>
<h3 id=unfair-model>Unfair model</h3>
<p>As detailed in <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, the concept of counterfactual fairness holds
under three levels of assumptions of increasing strength.</p>
<p>The first of such levels is <strong>Level 1</strong>, where \(\hat{Y}\) is built using only the observable non-descendants of \(A\).
This only requires <strong>partial</strong> causal ordering and no further causal assumptions, but in many problems there will be few, if any,
observables which are not descendants of protected demographic factors.</p>
<p>For this dataset, since <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> are all biased by ethnicity and gender, we cannot use any observed
features to construct a Level 1 counterfactually fair predictor as described in Level 1.</p>
<p>Instead (and in order to compare the performance with Level 2 and 3 models) we will build two <em>unfair baselines</em>.</p>
<ul>
<li>A <strong>Full</strong> model, which will be trained with the totality of the variables</li>
<li>An <strong>Unaware</strong> model (FTU), which will be trained will all the variables, except the protected attributes \(A\).</li>
</ul>
<p>Let&rsquo;s proceed with calculating the <strong>Full</strong> model.</p>
<h3 id=full-model>Full model</h3>
<p>As mentioned previously, the full model will be a simple linear regression in order to predict <code>ZFYA</code> using all of the variables.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>from</span> <span style=color:#555>sklearn.linear_model</span> <span style=font-weight:700>import</span> LinearRegression

linreg_unfair <span style=font-weight:700>=</span> LinearRegression()
</code></pre></div><p>The inputs will then be the totality of the variabes (protected variables \(A\), as well as <code>UGPA</code> and <code>LSAT</code>).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=font-weight:700>as</span> <span style=color:#555>np</span>

X <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (
        df_train[A],
        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
    )
)
<span style=color:#999>print</span>(X)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[[ 0.   0.   0.  ...  1.   3.1 39. ]
 [ 0.   0.   0.  ...  1.   3.5 36. ]
 [ 0.   0.   0.  ...  1.   3.9 46. ]
 ...
 [ 0.   0.   0.  ...  1.   2.9 33. ]
 [ 0.   0.   0.  ...  0.   2.9 31. ]
 [ 0.   0.   0.  ...  0.   3.6 39. ]]
</code></pre></div><p>As for our target, we are trying to predict <code>ZFYA</code> (first year average grade).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>y <span style=font-weight:700>=</span> df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>]
y[:<span style=color:#099>10</span>]
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>10454    0.56
14108    0.60
20624   -0.14
8316     0.20
14250    0.02
18909   -1.47
8949     1.36
1658     0.39
23340    0.10
26884    0.48
Name: ZFYA, dtype: float64
</code></pre></div><p>We fit the model:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>fit(X, y)
</code></pre></div><p>And perform some predictions on the test subset.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>X_test <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (
        df_test[A],
        np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
        np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
    )
)
X_test
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[ 0. ,  0. ,  0. , ...,  0. ,  3.4, 32. ],
       [ 0. ,  0. ,  0. , ...,  1. ,  3.5, 41. ],
       [ 0. ,  0. ,  0. , ...,  1. ,  3.9, 42. ],
       ...,
       [ 0. ,  0. ,  0. , ...,  0. ,  2.3, 28. ],
       [ 0. ,  0. ,  0. , ...,  0. ,  3.3, 36. ],
       [ 0. ,  0. ,  0. , ...,  0. ,  2.9, 37. ]])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>predictions_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>predict(X_test)
predictions_unfair
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([ 0.08676147,  0.34942627,  0.4609375 , ..., -0.25949097,
        0.19308472,  0.14471436])
</code></pre></div><p>We will also calculate the <em>unfair model</em> score for future use.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>score_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>score(X_test, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
<span style=color:#999>print</span>(score_unfair)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.12701634112845117
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>from</span> <span style=color:#555>sklearn.metrics</span> <span style=font-weight:700>import</span> mean_squared_error

RMSE_unfair <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_unfair))
<span style=color:#999>print</span>(RMSE_unfair)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.8666709890234552
</code></pre></div><h3 id=fairness-through-unawareness--ftu>Fairness through unawareness (FTU)</h3>
<p>As also mentioned in <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, the second baseline we will use is an <strong><strong>Unaware</strong></strong> model (FTU), which will be trained will all the variables, except the protected attributes \(A\).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_ftu <span style=font-weight:700>=</span> LinearRegression()
</code></pre></div><p>We will create the inputs as previously, but without using the protected attributes, \(A\).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>X_ftu <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (
        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
    )
)
X_ftu
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[ 3.1, 39. ],
       [ 3.5, 36. ],
       [ 3.9, 46. ],
       ...,
       [ 2.9, 33. ],
       [ 2.9, 31. ],
       [ 3.6, 39. ]])
</code></pre></div><p>And we fit the model:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_ftu <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>fit(X_ftu, y)
</code></pre></div><p>Again, let&rsquo;s perform some predictions on the test subset.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>X_ftu_test <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>), np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>))
)
X_ftu_test
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[ 3.4, 32. ],
       [ 3.5, 41. ],
       [ 3.9, 42. ],
       ...,
       [ 2.3, 28. ],
       [ 3.3, 36. ],
       [ 2.9, 37. ]])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>predictions_ftu <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>predict(X_ftu_test)
predictions_ftu
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([-0.06909331,  0.35516229,  0.50304555, ..., -0.53109868,
        0.08204563,  0.0226846 ])
</code></pre></div><p>As previously, let&rsquo;s calculate this model&rsquo;s score.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>ftu_score <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>score(X_ftu_test, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
<span style=color:#999>print</span>(ftu_score)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.0917442226187073
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>RMSE_ftu <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_ftu))
<span style=color:#999>print</span>(RMSE_ftu)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.8840061503773576
</code></pre></div><h3 id=latent-variable-model>Latent variable model</h3>
<p>Still according to <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, a <strong><strong>Level 2</strong></strong> approach will model latent ‘fair’ variables which are parents of observed variables.</p>
<p>If we consider a predictor parameterised by \(\theta\), such as:</p>
<p>\[
\hat{Y} \equiv g_\theta (U, X_{\nsucc A})
\]</p>
<p>with \(X_{\nsucc A} \subseteq X\) are non-descendants of \(A\).
Assuming a loss function \(l(\cdot,\cdot)\) and training data \(\mathcal{D}\equiv\{(A^{(i), X^{(i)}, Y^{(i)}})\}\), for \(i=1,2\dots,n\), the empirical loss is defined as</p>
<p>\[
L(\theta)\equiv \sum_{i=1}^n \mathbb{E}[l(y^{(i)},g_\theta(U^{(i)}, x^{(i)}_{\nsucc A}))]/n
\]</p>
<p>which has to be minimised in order to \(\theta\). Each \(n\) expectation is with respect to random variable \(U^{(i)}\) such that</p>
<p>\[
U^{(i)}\sim P_{\mathcal{M}}(U|x^{(i)}, a^{(i)})
\]</p>
<p>where \(P_{\mathcal{M}}(U|x,a)\) is the conditional distribution of the background variables as given by a causal model \(M\) that is available by assumption.</p>
<p>If this expectation cannot be calculated analytically, Markov chain Monte Carlo (MCMC) can be used to approximate it as in the following algorithm.</p>
<p>We will follow the model specified in the original paper, where the latent variable considered is \(K\), which represents a student&rsquo;s <strong><strong>knowledge</strong></strong>.
\(K\) will affect <code>GPA</code>, <code>LSAT</code> and the outcome, <code>FYA</code>.
The model can be defined by:</p>
<p>\begin{aligned}
GPA &\sim \mathcal{N}(GPA_0 + w_{GPA}^KK + w_{GPA}^RR + w_{GPA}^SS, \sigma_{GPA}) \\
LSAT &\sim \text{Po}(\exp(LSAT_0 + w_{LSAT}^KK + w_{LSAT}^RR + w_L^SS)) \\
FYA &\sim \mathcal{N}(w_{FYA}^KK + w_{FYA}^RR + w_{FYA}^SS, 1) \\
K &\sim \mathcal{N}(0,1)
\end{aligned}</p>
<p>The priors used will be:</p>
<p>\begin{aligned}
GPA_0 &\sim \mathcal{N}(0, 1) \\
LSAT_0 &\sim \mathcal{N}(0, 1) \\
GPA_0 &\sim \mathcal{N}(0, 1)
\end{aligned}</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>pymc3</span> <span style=font-weight:700>as</span> <span style=color:#555>pm</span>

K <span style=font-weight:700>=</span> <span style=color:#999>len</span>(A)


<span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>MCMC</span>(data, samples<span style=font-weight:700>=</span><span style=color:#099>1000</span>):

    N <span style=font-weight:700>=</span> <span style=color:#999>len</span>(data)
    a <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>array(data[A])

    model <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Model()

    <span style=font-weight:700>with</span> model:
        <span style=color:#998;font-style:italic># Priors</span>
        k <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;k&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>, shape<span style=font-weight:700>=</span>(<span style=color:#099>1</span>, N))
        gpa0 <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;gpa0&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>)
        lsat0 <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;lsat0&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>)
        w_k_gpa <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_k_gpa&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>)
        w_k_lsat <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_k_lsat&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>)
        w_k_zfya <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_k_zfya&#34;</span>, mu<span style=font-weight:700>=</span><span style=color:#099>0</span>, sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>)

        w_a_gpa <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_a_gpa&#34;</span>, mu<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>zeros(K), sigma<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>ones(K), shape<span style=font-weight:700>=</span>K)
        w_a_lsat <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_a_lsat&#34;</span>, mu<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>zeros(K), sigma<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>ones(K), shape<span style=font-weight:700>=</span>K)
        w_a_zfya <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(<span style=color:#b84>&#34;w_a_zfya&#34;</span>, mu<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>zeros(K), sigma<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>ones(K), shape<span style=font-weight:700>=</span>K)

        sigma_gpa_2 <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>InverseGamma(<span style=color:#b84>&#34;sigma_gpa_2&#34;</span>, alpha<span style=font-weight:700>=</span><span style=color:#099>1</span>, beta<span style=font-weight:700>=</span><span style=color:#099>1</span>)

        mu <span style=font-weight:700>=</span> gpa0 <span style=font-weight:700>+</span> (w_k_gpa <span style=font-weight:700>*</span> k) <span style=font-weight:700>+</span> pm<span style=font-weight:700>.</span>math<span style=font-weight:700>.</span>dot(a, w_a_gpa)

        <span style=color:#998;font-style:italic># Observed data</span>
        gpa <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(
            <span style=color:#b84>&#34;gpa&#34;</span>,
            mu<span style=font-weight:700>=</span>mu,
            sigma<span style=font-weight:700>=</span>pm<span style=font-weight:700>.</span>math<span style=font-weight:700>.</span>sqrt(sigma_gpa_2),
            observed<span style=font-weight:700>=</span><span style=color:#999>list</span>(data[<span style=color:#b84>&#34;UGPA&#34;</span>]),
            shape<span style=font-weight:700>=</span>(<span style=color:#099>1</span>, N),
        )
        lsat <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Poisson(
            <span style=color:#b84>&#34;lsat&#34;</span>,
            pm<span style=font-weight:700>.</span>math<span style=font-weight:700>.</span>exp(lsat0 <span style=font-weight:700>+</span> w_k_lsat <span style=font-weight:700>*</span> k <span style=font-weight:700>+</span> pm<span style=font-weight:700>.</span>math<span style=font-weight:700>.</span>dot(a, w_a_lsat)),
            observed<span style=font-weight:700>=</span><span style=color:#999>list</span>(data[<span style=color:#b84>&#34;LSAT&#34;</span>]),
            shape<span style=font-weight:700>=</span>(<span style=color:#099>1</span>, N),
        )
        zfya <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Normal(
            <span style=color:#b84>&#34;zfya&#34;</span>,
            mu<span style=font-weight:700>=</span>w_k_zfya <span style=font-weight:700>*</span> k <span style=font-weight:700>+</span> pm<span style=font-weight:700>.</span>math<span style=font-weight:700>.</span>dot(a, w_a_zfya),
            sigma<span style=font-weight:700>=</span><span style=color:#099>1</span>,
            observed<span style=font-weight:700>=</span><span style=color:#999>list</span>(data[<span style=color:#b84>&#34;ZFYA&#34;</span>]),
            shape<span style=font-weight:700>=</span>(<span style=color:#099>1</span>, N),
        )

        step <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>Metropolis()
        trace <span style=font-weight:700>=</span> pm<span style=font-weight:700>.</span>sample(samples, step, progressbar <span style=font-weight:700>=</span> <span style=font-weight:700>False</span>)

    <span style=font-weight:700>return</span> trace
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_estimates <span style=font-weight:700>=</span> MCMC(df_train)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Metropolis: [sigma_gpa_2]
&gt;Metropolis: [w_a_zfya]
&gt;Metropolis: [w_a_lsat]
&gt;Metropolis: [w_a_gpa]
&gt;Metropolis: [w_k_zfya]
&gt;Metropolis: [w_k_lsat]
&gt;Metropolis: [w_k_gpa]
&gt;Metropolis: [lsat0]
&gt;Metropolis: [gpa0]
&gt;Metropolis: [k]
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 77 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.
</code></pre></div><p>Let&rsquo;s plot a single trace for \(k^{(i)}\).</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=font-weight:700>as</span> <span style=color:#555>plt</span>
<span style=font-weight:700>import</span> <span style=color:#555>seaborn</span> <span style=font-weight:700>as</span> <span style=color:#555>sns</span>
<span style=font-weight:700>from</span> <span style=color:#555>plotutils</span> <span style=font-weight:700>import</span> <span style=font-weight:700>*</span>

<span style=color:#998;font-style:italic># Thin the samples before plotting</span>
k_trace <span style=font-weight:700>=</span> train_estimates[<span style=color:#b84>&#34;k&#34;</span>][:, <span style=color:#099>0</span>]<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>)[<span style=color:#099>0</span>::<span style=color:#099>100</span>]
plt<span style=font-weight:700>.</span>subplot(<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>1</span>)
plt<span style=font-weight:700>.</span>hist(k_trace, color<span style=font-weight:700>=</span>colours[<span style=color:#099>0</span>], bins<span style=font-weight:700>=</span><span style=color:#099>100</span>)
plt<span style=font-weight:700>.</span>subplot(<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>2</span>)
plt<span style=font-weight:700>.</span>scatter(<span style=color:#999>range</span>(<span style=color:#999>len</span>(k_trace)), k_trace, s<span style=font-weight:700>=</span><span style=color:#099>1</span>, c<span style=font-weight:700>=</span>colours[<span style=color:#099>0</span>])
plt<span style=font-weight:700>.</span>show()
</code></pre></div><figure><img src=/ox-hugo/70405364f6b478b4fb212a0c3f658be9738e8156.png>
</figure>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_k <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>mean(train_estimates[<span style=color:#b84>&#34;k&#34;</span>], axis<span style=font-weight:700>=</span><span style=color:#099>0</span>)<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>)
train_k
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[-0.00531227],
       [-0.13776645],
       [-0.02434896],
       ...,
       [ 0.02273157],
       [-0.2767904 ],
       [-0.15568193]])
</code></pre></div><p>We can now estimate \(k\) using the test data:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>test_map_estimates <span style=font-weight:700>=</span> MCMC(df_test)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Metropolis: [sigma_gpa_2]
&gt;Metropolis: [w_a_zfya]
&gt;Metropolis: [w_a_lsat]
&gt;Metropolis: [w_a_gpa]
&gt;Metropolis: [w_k_zfya]
&gt;Metropolis: [w_k_lsat]
&gt;Metropolis: [w_k_gpa]
&gt;Metropolis: [lsat0]
&gt;Metropolis: [gpa0]
&gt;Metropolis: [k]
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 59 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.
</code></pre></div><p>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 35 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>test_k <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>mean(test_map_estimates[<span style=color:#b84>&#34;k&#34;</span>], axis<span style=font-weight:700>=</span><span style=color:#099>0</span>)<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>)
test_k
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[ 0.36632736],
       [ 0.09415253],
       [ 0.03452081],
       ...,
       [ 0.00471526],
       [-0.09991792],
       [ 0.19771541]])
</code></pre></div><p>We now build the Level 2 predictor, using \(k\) as the input.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_latent <span style=font-weight:700>=</span> LinearRegression()
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_latent <span style=font-weight:700>=</span> linreg_latent<span style=font-weight:700>.</span>fit(train_k, df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>predictions_latent <span style=font-weight:700>=</span> linreg_latent<span style=font-weight:700>.</span>predict(test_k)
predictions_latent
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([0.18043648, 0.1160878 , 0.10198943, ..., 0.09494268, 0.07020488,
       0.14057256])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>latent_score <span style=font-weight:700>=</span> linreg_latent<span style=font-weight:700>.</span>score(test_k, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
<span style=color:#999>print</span>(latent_score)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.0027649341873033917
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>RMSE_latent <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_latent))
<span style=color:#999>print</span>(RMSE_latent)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.9262963924423802
</code></pre></div><h3 id=additive-error-model>Additive error model</h3>
<p>Finally, in <strong><strong>Level 3</strong></strong>, we model <code>GPA</code>, <code>LSAT</code>, and <code>FYA</code> as continuous variables with additive error terms
independent of race and sex<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>.</p>
<p>This corresponds to</p>
<p>\begin{aligned}
GPA &= b_G + w^R_{GPA}R + w^S_{GPA}S + \epsilon_{GPA}, \epsilon_{GPA} \sim p(\epsilon_{GPA}) \\
LSAT &= b_L + w^R_{LSAT}R + w^S_{LSAT}S + \epsilon_{LSAT}, \epsilon_{LSAT} \sim p(\epsilon_{LSAT}) \\
FYA &= b_{FYA} + w^R_{FYA}R + w^S_{FYA}S + \epsilon_{FYA} , \epsilon_{FYA} \sim p(\epsilon_{FYA})
\end{aligned}</p>
<p>We estimate the error terms \(\epsilon_{GPA}, \epsilon_{LSAT}\) by first fitting two models that each use race and sex to individually
predict <code>GPA</code> and <code>LSAT</code>. We then compute the residuals of each model (<em>e.g.</em>, \(\epsilon_{GPA} =GPA−\hat{Y}_{GPA}(R, S)\)).
We use these residual estimates of \(\epsilon_{GPA}, \epsilon_{LSAT}\) to predict \(FYA\). In <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> this is called <em>Fair Add</em>.</p>
<p>Since the process is similar for the individual predictions for <code>GPA</code> and <code>LSAT</code>, we will write a method to avoid repetion.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>calculate_epsilon</span>(data, var_name, protected_attr):
    X <span style=font-weight:700>=</span> data[protected_attr]
    y <span style=font-weight:700>=</span> data[var_name]

    linreg <span style=font-weight:700>=</span> LinearRegression()
    linreg <span style=font-weight:700>=</span> linreg<span style=font-weight:700>.</span>fit(X, y)

    predictions <span style=font-weight:700>=</span> linreg<span style=font-weight:700>.</span>predict(X)

    <span style=font-weight:700>return</span> data[var_name] <span style=font-weight:700>-</span> predictions
</code></pre></div><p>Let&rsquo;s apply it to each variable, individually.
First we calculate \(\epsilon_{GPA}\):</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>epsilons_gpa <span style=font-weight:700>=</span> calculate_epsilon(df, <span style=color:#b84>&#34;UGPA&#34;</span>, A)
epsilons_gpa
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0       -0.242
1       -0.342
2       -0.100
5       -0.873
6        0.058
         ...
27472    0.800
27473    0.358
27474    0.658
27475   -0.300
27476   -0.100
Name: UGPA, Length: 21791, dtype: float64
</code></pre></div><p>Next, we calculate \(\epsilon_{LSAT}\):</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>epsilons_LSAT <span style=font-weight:700>=</span> calculate_epsilon(df, <span style=color:#b84>&#34;LSAT&#34;</span>, A)
epsilons_LSAT
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0        1.789
1       -1.211
2       -7.689
5        5.055
6       -0.211
         ...
27472   -4.689
27473    0.789
27474   -1.211
27475   -6.689
27476   -9.689
Name: LSAT, Length: 21791, dtype: float64
</code></pre></div><p>Let&rsquo;s visualise the \(\epsilon\) distribution quickly:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=font-weight:700>as</span> <span style=color:#555>plt</span>
<span style=font-weight:700>import</span> <span style=color:#555>seaborn</span> <span style=font-weight:700>as</span> <span style=color:#555>sns</span>

plt<span style=font-weight:700>.</span>subplot(<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>1</span>)
plt<span style=font-weight:700>.</span>hist(epsilons_gpa, color<span style=font-weight:700>=</span>colours[<span style=color:#099>0</span>], bins<span style=font-weight:700>=</span><span style=color:#099>100</span>)
plt<span style=font-weight:700>.</span>title(<span style=color:#b84>&#34;$\epsilon_</span><span style=color:#b84>{GPA}</span><span style=color:#b84>$&#34;</span>)
plt<span style=font-weight:700>.</span>xlabel(<span style=color:#b84>&#34;$\epsilon_</span><span style=color:#b84>{GPA}</span><span style=color:#b84>$&#34;</span>)

plt<span style=font-weight:700>.</span>subplot(<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>2</span>)
plt<span style=font-weight:700>.</span>hist(epsilons_LSAT, color<span style=font-weight:700>=</span>colours[<span style=color:#099>1</span>], bins<span style=font-weight:700>=</span><span style=color:#099>100</span>)
plt<span style=font-weight:700>.</span>title(<span style=color:#b84>&#34;$\epsilon_</span><span style=color:#b84>{LSAT}</span><span style=color:#b84>$&#34;</span>)
plt<span style=font-weight:700>.</span>xlabel(<span style=color:#b84>&#34;$\epsilon_</span><span style=color:#b84>{LSAT}</span><span style=color:#b84>$&#34;</span>)
plt<span style=font-weight:700>.</span>show()
</code></pre></div><figure><img src=/ox-hugo/1fbff0daab700f9804c68166ea84bef906ac3f93.png>
</figure>
<p>We finally use the calculated \(\epsilon\) to train a model in order to predict <code>FYA</code>.
We start by getting the subset of the \(\epsilon\) which match the training indices.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>X <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (
        np<span style=font-weight:700>.</span>array(epsilons_gpa[df_train<span style=font-weight:700>.</span>index])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
        np<span style=font-weight:700>.</span>array(epsilons_LSAT[df_train<span style=font-weight:700>.</span>index])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
    )
)
X
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([[-0.24179687,  1.7890625 ],
       [ 0.15820312, -1.2109375 ],
       [ 0.55820312,  8.7890625 ],
       ...,
       [-0.44179688, -4.2109375 ],
       [-0.25087891, -4.7265625 ],
       [ 0.39980469,  1.31054688]])
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>linreg_fair_add <span style=font-weight:700>=</span> LinearRegression()

linreg_fair_add <span style=font-weight:700>=</span> linreg_fair_add<span style=font-weight:700>.</span>fit(
    X,
    df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
)
</code></pre></div><p>We now use this model to calculate the predictions</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>X_test <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
    (
        np<span style=font-weight:700>.</span>array(epsilons_gpa[df_test<span style=font-weight:700>.</span>index])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
        np<span style=font-weight:700>.</span>array(epsilons_LSAT[df_test<span style=font-weight:700>.</span>index])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
    )
)

predictions_fair_add <span style=font-weight:700>=</span> linreg_fair_add<span style=font-weight:700>.</span>predict(X_test)
predictions_fair_add
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>array([-0.04394693,  0.24454891,  0.35558793, ..., -0.38844376,
        0.06136776,  0.01295201])
</code></pre></div><p>And as previously, we calculate the model&rsquo;s score:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fair_add_score <span style=font-weight:700>=</span> linreg_fair_add<span style=font-weight:700>.</span>score(X_test, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
<span style=color:#999>print</span>(fair_add_score)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.04475841449183948
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>RMSE_fair_add <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_fair_add))
<span style=color:#999>print</span>(RMSE_fair_add)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>0.9065835039365202
</code></pre></div><h3 id=comparison>Comparison</h3>
<p>The scores, so far, are:</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;Unfair score:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>score_unfair<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;FTU score:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>ftu_score<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;L2 score:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>latent_score<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;Fair add score:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>fair_add_score<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>Unfair score:	0.12701634112845117
FTU score:	0.0917442226187073
L2 score:	0.0027649341873033917
Fair add score:	0.04475841449183948
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;Unfair RMSE:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>RMSE_unfair<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;FTU RMSE:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>RMSE_ftu<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;L2 RMSE:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>RMSE_latent<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
<span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;Fair add RMSE:</span><span style=color:#b84>\t</span><span style=color:#b84>{</span>RMSE_fair_add<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>Unfair RMSE:	0.8666709890234552
FTU RMSE:	0.8840061503773576
L2 RMSE:	0.9262963924423802
Fair add RMSE:	0.9065835039365202
</code></pre></div><h2 id=measuring-counterfactual-fairness>Measuring counterfactual fairness</h2>
<p>First, we will measure two quantities, the <strong><strong>Statistical Parity Difference</strong></strong> (SPD)<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> and <strong><strong>Disparate impact</strong></strong> (DI)<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>.</p>
<h3 id=statistical-parity-difference-disparate-impact>Statistical Parity Difference / Disparate Impact</h3>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>from</span> <span style=color:#555>fairlearn.metrics</span> <span style=font-weight:700>import</span> demographic_parity_difference, demographic_parity_ratio

parities <span style=font-weight:700>=</span> []
impacts <span style=font-weight:700>=</span> []

<span style=font-weight:700>for</span> a <span style=font-weight:700>in</span> A:
    parity <span style=font-weight:700>=</span> demographic_parity_difference(df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>], df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                                sensitive_features <span style=font-weight:700>=</span> df_train[a])
    di <span style=font-weight:700>=</span> demographic_parity_ratio(df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>], df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                                sensitive_features <span style=font-weight:700>=</span> df_train[a])
    parities<span style=font-weight:700>.</span>append(parity)
    impacts<span style=font-weight:700>.</span>append(di)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df_parities <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame({<span style=color:#b84>&#39;protected&#39;</span>:A,<span style=color:#b84>&#39;parity&#39;</span>:parities,<span style=color:#b84>&#39;impact&#39;</span>:impacts})
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=font-weight:700>as</span> <span style=color:#555>plt</span>
<span style=font-weight:700>from</span> <span style=color:#555>plotutils</span> <span style=font-weight:700>import</span> <span style=font-weight:700>*</span>

fig <span style=font-weight:700>=</span> plt<span style=font-weight:700>.</span>figure()

ax <span style=font-weight:700>=</span> fig<span style=font-weight:700>.</span>add_subplot(<span style=color:#099>111</span>)
ax2 <span style=font-weight:700>=</span> ax<span style=font-weight:700>.</span>twinx()

fig<span style=font-weight:700>.</span>suptitle(<span style=color:#b84>&#39;Statistical Parity Difference and Disparate Impact&#39;</span>)

width <span style=font-weight:700>=</span> <span style=color:#099>0.4</span>
df_parities<span style=font-weight:700>.</span>plot(x <span style=font-weight:700>=</span><span style=color:#b84>&#39;protected&#39;</span>, y <span style=font-weight:700>=</span> <span style=color:#b84>&#39;parity&#39;</span>, kind <span style=font-weight:700>=</span> <span style=color:#b84>&#39;bar&#39;</span>, ax <span style=font-weight:700>=</span> ax, width <span style=font-weight:700>=</span> width,
       position<span style=font-weight:700>=</span><span style=color:#099>1</span>, color<span style=font-weight:700>=</span>colours[<span style=color:#099>0</span>], legend<span style=font-weight:700>=</span><span style=font-weight:700>False</span>)

df_parities<span style=font-weight:700>.</span>plot(x <span style=font-weight:700>=</span><span style=color:#b84>&#39;protected&#39;</span>, y <span style=font-weight:700>=</span> <span style=color:#b84>&#39;impact&#39;</span>, kind <span style=font-weight:700>=</span> <span style=color:#b84>&#39;bar&#39;</span>, ax <span style=font-weight:700>=</span> ax2, width <span style=font-weight:700>=</span> width,
       position <span style=font-weight:700>=</span> <span style=color:#099>0</span>, color <span style=font-weight:700>=</span> colours[<span style=color:#099>1</span>], legend <span style=font-weight:700>=</span> <span style=font-weight:700>False</span>)

ax<span style=font-weight:700>.</span>axhline(y <span style=font-weight:700>=</span> <span style=color:#099>0.1</span>, linestyle <span style=font-weight:700>=</span> <span style=color:#b84>&#39;dashed&#39;</span>, alpha <span style=font-weight:700>=</span> <span style=color:#099>0.7</span>, color <span style=font-weight:700>=</span> colours[<span style=color:#099>0</span>])
ax2<span style=font-weight:700>.</span>axhline(y <span style=font-weight:700>=</span> <span style=color:#099>0.55</span>, linestyle <span style=font-weight:700>=</span> <span style=color:#b84>&#39;dashed&#39;</span>, alpha <span style=font-weight:700>=</span> <span style=color:#099>0.7</span>, color <span style=font-weight:700>=</span> colours[<span style=color:#099>1</span>])


patches, labels <span style=font-weight:700>=</span> ax<span style=font-weight:700>.</span>get_legend_handles_labels()
ax<span style=font-weight:700>.</span>legend(patches, [<span style=color:#b84>&#39;Stat Parity Diff&#39;</span>], loc <span style=font-weight:700>=</span> <span style=color:#b84>&#39;upper left&#39;</span>)

patches, labels <span style=font-weight:700>=</span> ax2<span style=font-weight:700>.</span>get_legend_handles_labels()
ax2<span style=font-weight:700>.</span>legend(patches, [<span style=color:#b84>&#39;Disparate Impact&#39;</span>], loc <span style=font-weight:700>=</span> <span style=color:#b84>&#39;upper right&#39;</span>)



labels <span style=font-weight:700>=</span> [item<span style=font-weight:700>.</span>get_text() <span style=font-weight:700>for</span> item <span style=font-weight:700>in</span> ax<span style=font-weight:700>.</span>get_xticklabels()]

<span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#999>len</span>(A)):
    labels[i] <span style=font-weight:700>=</span> A[i]

ax<span style=font-weight:700>.</span>set_xticklabels(labels)
ax<span style=font-weight:700>.</span>set_xlabel(<span style=color:#b84>&#39;Protected Features&#39;</span>)

ax<span style=font-weight:700>.</span>set_ylabel(<span style=color:#b84>&#39;Statistical Parity Difference&#39;</span>)
ax2<span style=font-weight:700>.</span>set_ylabel(<span style=color:#b84>&#39;Disparate Impact&#39;</span>)

plt<span style=font-weight:700>.</span>show()
</code></pre></div><figure><img src=/ox-hugo/938fda75bc5f941252060110b289058e5d383f09.png>
</figure>
<h3 id=finding-sensitive-features>Finding sensitive features</h3>
<p>Typically a \(SPD > 0.1\) and a \(DI &lt; 0.9\) might indicate discrimination on those features.
All <span class=underline>protected attributes</span> fail the SPD test and, in our dataset, we have two features (<code>Hispanic</code> and <code>Mexican</code>) which clearly fail the DI test.</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=font-weight:700>for</span> a <span style=font-weight:700>in</span> [<span style=color:#b84>&#34;Mexican&#34;</span>, <span style=color:#b84>&#34;Hispanic&#34;</span>]:
    spd <span style=font-weight:700>=</span> demographic_parity_difference(y_true<span style=font-weight:700>=</span>df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                        y_pred<span style=font-weight:700>=</span>df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                        sensitive_features <span style=font-weight:700>=</span> df_train[a])
    <span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;SPD(</span><span style=color:#b84>{</span>a<span style=color:#b84>}</span><span style=color:#b84>) = </span><span style=color:#b84>{</span>spd<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
    di <span style=font-weight:700>=</span> demographic_parity_ratio(y_true<span style=font-weight:700>=</span>df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                  y_pred<span style=font-weight:700>=</span>df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>],
                                  sensitive_features <span style=font-weight:700>=</span> df_train[a])
    <span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;DI(</span><span style=color:#b84>{</span>a<span style=color:#b84>}</span><span style=color:#b84>) = </span><span style=color:#b84>{</span>di<span style=color:#b84>}</span><span style=color:#b84>&#34;</span>)
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>SPD(Mexican) = 0.0014017257538768636
DI(Mexican) = 0.5556529360210342
SPD(Hispanic) = 0.003272247102713093
DI(Hispanic) = 0.34227833235466826
</code></pre></div><section class=footnotes role=doc-endnotes>
<hr>
<ol>
<li id=fn:1 role=doc-endnote>
<p>: McIntyre, Frank, and Michael Simkovic. &ldquo;Are law degrees as valuable to minorities?.&rdquo; International Review of Law and Economics 53 (2018): 23-37.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
<li id=fn:2 role=doc-endnote>
<p>: Kusner, Matt J., Joshua Loftus, Chris Russell, and Ricardo Silva. &ldquo;Counterfactual fairness.&rdquo; In Advances in neural information processing systems, pp. 4066-4076. 2017.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
<li id=fn:3 role=doc-endnote>
<p>: That may in turn be correlated with one-another.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
<li id=fn:4 role=doc-endnote>
<p>: See {ref}`fairness:demographic-parity-difference`.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
<li id=fn:5 role=doc-endnote>
<p>: See {ref}`fairness:disparate-impact`.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p>
</li>
</ol>
</section>
</div>
</article>
<div id=footer-post-container>
<div id=footer-post>
<div id=nav-footer style=display:none>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/map/>All pages</a></li>
<li><a href=/search.html>Search</a></li>
</ul>
</div>
<div id=toc-footer style=display:none>
<nav id=TableOfContents>
<ul>
<li><a href=#building-counterfactually-fair-models>Building counterfactually fair models</a>
<ul>
<li><a href=#data>Data</a></li>
<li><a href=#pre-processing>Pre-processing</a></li>
<li><a href=#protected-attributes>Protected attributes</a></li>
<li><a href=#training-and-testing-subsets>Training and testing subsets</a></li>
</ul>
</li>
<li><a href=#models>Models</a>
<ul>
<li><a href=#unfair-model>Unfair model</a></li>
<li><a href=#full-model>Full model</a></li>
<li><a href=#fairness-through-unawareness--ftu>Fairness through unawareness (FTU)</a></li>
<li><a href=#latent-variable-model>Latent variable model</a></li>
<li><a href=#additive-error-model>Additive error model</a></li>
<li><a href=#comparison>Comparison</a></li>
</ul>
</li>
<li><a href=#measuring-counterfactual-fairness>Measuring counterfactual fairness</a>
<ul>
<li><a href=#statistical-parity-difference-disparate-impact>Statistical Parity Difference / Disparate Impact</a></li>
<li><a href=#finding-sensitive-features>Finding sensitive features</a></li>
</ul>
</li>
</ul>
</nav>
</div>
<div id=share-footer style=display:none>
<ul>
<li>
<a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label=Facebook>
<i class="fab fa-facebook fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label=Twitter>
<i class="fab fa-twitter fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Linkedin>
<i class="fab fa-linkedin fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label=Pinterest>
<i class="fab fa-pinterest fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label=Email>
<i class="fas fa-envelope fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Pocket>
<i class="fab fa-get-pocket fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=reddit>
<i class="fab fa-reddit fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20%60FYA%60." aria-label=Tumblr>
<i class="fab fa-tumblr fa-lg" aria-hidden=true></i>
</a>
</li>
<li>
<a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News">
<i class="fab fa-hacker-news fa-lg" aria-hidden=true></i>
</a>
</li>
</ul>
</div>
<div id=actions-footer>
<a id=menu-toggle class=icon href=# onclick="return $('#nav-footer').toggle(),!1" aria-label=Menu>
<i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick="return $('#toc-footer').toggle(),!1" aria-label=TOC>
<i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick="return $('#share-footer').toggle(),!1" aria-label=Share>
<i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast')" aria-label="Top of Page">
<i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a>
</div>
</div>
</div>
<footer id=footer>
<div class=footer-left>
Copyright &copy; 2022 Rui Vieira
</div>
<div class=footer-right>
<nav>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/map/>All pages</a></li>
<li><a href=/search.html>Search</a></li>
</ul>
</nav>
</div>
</footer>
</div>
</body>
<link rel=stylesheet href=/css/fa.min.css>
<script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/main.js></script>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
</html>