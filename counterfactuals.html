<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script><script src=https://unpkg.com/@alpinejs/intersect@3.x.x/dist/cdn.min.js></script><script src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script><script type=module src=https://ruivieira.dev/js/deeplinks/deeplinks.js></script><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/fonts/vollkorn/Vollkorn-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=https://ruivieira.dev/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Counterfactuals · Rui Vieira</title>
<link rel=canonical href=https://ruivieira.dev/counterfactuals.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Counterfactuals"><meta property="og:description" content="A special type of Explainability.
DesiderataAccording to Verma et al 1 the counterfactual desiderata is:
Validity Actionability Sparsity Data manifold closeness Causality Amortised inference ValidityWe assume that a counterfactual is valid if it solves the optimisation as states in Wachter et al2. If we defined the loss function as
$$ L(x,x^{\prime},y^{\prime},\lambda)=\lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime}), $$
we can define the counterfactual as
$$ \arg \underset{x^{\prime}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime}) $$
where:
$x \in \mathcal{X}$ is the original data point $x^{\prime} \in \mathcal{X}$ is the counterfactual $y^{\prime} \in \mathcal{Y}$ is the desired label $d$ is a distance metric to measure the distance between $x$ and $x^{\prime}$."><meta property="og:type" content="article"><meta property="og:url" content="https://ruivieira.dev/counterfactuals.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2024-01-28T14:51:25+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Counterfactuals"><meta name=twitter:description content="A special type of Explainability.
DesiderataAccording to Verma et al 1 the counterfactual desiderata is:
Validity Actionability Sparsity Data manifold closeness Causality Amortised inference ValidityWe assume that a counterfactual is valid if it solves the optimisation as states in Wachter et al2. If we defined the loss function as
$$ L(x,x^{\prime},y^{\prime},\lambda)=\lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime}), $$
we can define the counterfactual as
$$ \arg \underset{x^{\prime}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime}) $$
where:
$x \in \mathcal{X}$ is the original data point $x^{\prime} \in \mathcal{X}$ is the counterfactual $y^{\prime} \in \mathcal{Y}$ is the desired label $d$ is a distance metric to measure the distance between $x$ and $x^{\prime}$."><link rel=stylesheet href=https://ruivieira.dev/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://ruivieira.dev/images/favicon.ico></head><body class="max-width mx-auto px3 ltr" x-data="{currentHeading: undefined}"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></span><br><div id=share style=display:none></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#desiderata :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#desiderata' }">Desiderata</a></li><li><a href=#validity :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#validity' }">Validity</a></li><li><a href=#actionability :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#actionability' }">Actionability</a></li><li><a href=#sparsity :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#sparsity' }">Sparsity</a></li><li><a href=#data-manifold-closeness :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#data-manifold-closeness' }">Data manifold closeness</a></li><li><a href=#causality :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#causality' }">Causality</a></li><li><a href=#amortised-inference :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#amortised-inference' }">Amortised inference</a></li><li><a href=#alternative-methods :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#alternative-methods' }">Alternative methods</a></li><li><a href=#constraint-solvers :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#constraint-solvers' }">Constraint solvers</a></li><li><a href=#resources :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#resources' }">Resources</a></li></ul></nav><h4>Related</h4><nav><ul><li class="header-post toc"><span class=backlink-count>1</span>
<a href=https://ruivieira.dev/explainability.html>Explainability</a></li><li class="header-post toc"><span class=backlink-count>1</span>
<a href>Index</a></li><li class="header-post toc"><span class=backlink-count>1</span>
<a href=https://ruivieira.dev/synthetic-data-generation.html>Synthetic Data Generation</a></li><li class="header-post toc"><span class=backlink-count>1</span>
<a href=https://ruivieira.dev/counterfactuals-with-constraint-solvers.html>Counterfactuals with Constraint Solvers</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Counterfactuals</h1><div class=meta><div class=postdate>Updated <time datetime="2024-01-28 14:51:25 +0000 GMT" itemprop=datePublished>2024-01-28</time>
<span class=commit-hash>(<a href=https://ruivieira.dev/log/index.html#0c79fa3>0c79fa3</a>)</span></div></div></header><div class=content itemprop=articleBody><p>A special type of <a href=https://ruivieira.dev/explainability.html>Explainability</a>.</p><h2 id=desiderata x-intersect="currentHeading = '#desiderata'">Desiderata</h2><p>According to Verma <em>et al</em> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> the counterfactual desiderata is:</p><ul><li><a href=#validity>Validity</a></li><li><a href=#actionability>Actionability</a></li><li><a href=#sparsity>Sparsity</a></li><li><a href=#data-manifold-closeness>Data manifold closeness</a></li><li><a href=#causality>Causality</a></li><li><a href=#amortised-inference>Amortised inference</a></li></ul><h3 id=validity x-intersect="currentHeading = '#validity'">Validity</h3><p>We assume that a counterfactual is <em>valid</em> if it solves the optimisation as states in Wachter <em>et al</em><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. If we defined the loss function as</p><p>$$
L(x,x^{\prime},y^{\prime},\lambda)=\lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime}),
$$</p><p>we can define the counterfactual as</p><p>$$
\arg \underset{x^{\prime}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime})
$$</p><p>where:</p><ul><li>$x \in \mathcal{X}$ is the original data point</li><li>$x^{\prime} \in \mathcal{X}$ is the counterfactual</li><li>$y^{\prime} \in \mathcal{Y}$ is the desired label</li><li>$d$ is a <a href=https://ruivieira.dev/distance-metrics.html>distance metric</a> to measure the distance between $x$ and $x^{\prime}$. this could be a <a href=https://ruivieira.dev/distance-metrics.html#manhattan-distance-l1>L1</a> or L2 distance, a quadratic distance, <em>etc.</em></li></ul><h3 id=actionability x-intersect="currentHeading = '#actionability'">Actionability</h3><p>Still according to <sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, <em>actionability</em> refers to the ability of a counterfactual method to separate between <em>mutable</em> and <em>immutable</em> features. Immutable, and additionally legally protected features, shouldn&rsquo;t be changed by a counterfactual implementation. Formally, if we defined our set of mutable (or <em>actionable</em>) features as $\mathcal{A}$, we have</p><p>$$
\arg \underset{x^{\prime} \in \mathcal{A}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime})
$$</p><h3 id=sparsity x-intersect="currentHeading = '#sparsity'">Sparsity</h3><p>According to <sup id=fnref2:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> Shorter counterfactuals are easier to understand and an effective counterfactual implementation should change the least amount of features as possible. If a <em>sparsity penalty</em> term is added to our definition</p><p>$$
g(x^{\prime}-x)
$$</p><p>which increases the more features are changed and could be a L0 or [Distance metrics#Manhattan distance L1|L1]] metric, for instance. We can then define the counterfactual as</p><p>$$
\arg \underset{x^{\prime} \in \mathcal{A}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime})+g(x^{\prime}-x)
$$</p><h3 id=data-manifold-closeness x-intersect="currentHeading = '#data-manifold-closeness'">Data manifold closeness</h3><p>Still according to <sup id=fnref3:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, <em>data manifold closeness</em> is the property which guarantees that the counterfactual will be as close to the training data as possible. This can translate into a more &ldquo;realistic&rdquo; counterfactual, since it is possible that the counterfactual would take extreme or never seen before values in order to satisfy the previous conditions. Formally, we can write a penalty term for the adherence to the training data manifold, $\mathcal{X}$ as $l(x^{\prime};\mathcal{X})$ and the define the counterfactual as</p><p>$$
\arg \underset{x^{\prime} \in \mathcal{A}}{\min}\underset{\lambda}{\max} \lambda\times(\hat{f}(x^{\prime})−y^{\prime})^2+d(x,x^{\prime})+g(x^{\prime}-x)+l(x^{\prime};\mathcal{X})
$$</p><h3 id=causality x-intersect="currentHeading = '#causality'">Causality</h3><p>Causality refers to the property where feature changes will impact dependent features. That is, we no longer assume that all features are independent. This implies that the counterfactual method needs to mantain the causal relations between features.</p><h3 id=amortised-inference x-intersect="currentHeading = '#amortised-inference'">Amortised inference</h3><p>Amortised inference refers to the property of a counterfactual search to provide multiple counterfactuals for a single data point.</p><h2 id=alternative-methods x-intersect="currentHeading = '#alternative-methods'">Alternative methods</h2><h3 id=constraint-solvers x-intersect="currentHeading = '#constraint-solvers'">Constraint solvers</h3><p>An alternative method to find counterfactuals is to use constraint solvers. This is explored more in-depth in <a href=https://ruivieira.dev/counterfactuals-with-constraint-solvers.html>Counterfactuals with Constraint Solvers</a>.</p><h3 id=resources x-intersect="currentHeading = '#resources'">Resources</h3><ul><li><a href=https://arxiv.org/abs/1909.09369>FACE: Feasible and Actionable Counterfactual Explanations</a></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Verma, Sahil, John Dickerson, and Keegan Hines. &ldquo;<em>Counterfactual Explanations for Machine Learning: A Review.</em>&rdquo; <em>arXiv preprint arXiv:2010.10596</em> (2020).&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Wachter, Sandra, Brent Mittelstadt, and Chris Russell. &ldquo;<em>Counterfactual explanations without opening the black box: Automated decisions and the GDPR.</em>&rdquo; <em>Harv. JL & Tech.</em> 31 (2017): 841.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref3:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#desiderata>Desiderata</a><ul><li><a href=#validity>Validity</a></li><li><a href=#actionability>Actionability</a></li><li><a href=#sparsity>Sparsity</a></li><li><a href=#data-manifold-closeness>Data manifold closeness</a></li><li><a href=#causality>Causality</a></li><li><a href=#amortised-inference>Amortised inference</a></li></ul></li><li><a href=#alternative-methods>Alternative methods</a><ul><li><a href=#constraint-solvers>Constraint solvers</a></li><li><a href=#resources>Resources</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2024 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=https://ruivieira.dev/css/fa.min.css><script src=https://ruivieira.dev/js/jquery-3.6.0.min.js></script><script src=https://ruivieira.dev/js/mark.min.js></script><script src=https://ruivieira.dev/js/main.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>