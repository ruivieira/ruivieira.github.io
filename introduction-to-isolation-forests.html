<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script src=https://unpkg.com/@alpinejs/intersect@3.x.x/dist/cdn.min.js></script>
<script src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script>
<script type=module src=/js/deeplinks/deeplinks.js></script>
<link rel=preload href=/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/prociono/Prociono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Introduction to Isolation Forests · Rui Vieira</title><link rel=canonical href=/introduction-to-isolation-forests.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Introduction to Isolation Forests"><meta property="og:description" content="Isolation Forests (IFs), presented in Liu1 et. al (2012), are a popular algorithm used for outlier classification. In a very simplified way, the method consists of building an ensemble of Isolation Trees (ITs) for a given data set and observations are deemed anomalies if they have short adjusted average path lengths on the ITs.
ITs, which will be covered shortly, have several properties in common with a fundamental data structure: the Binary Search Tree (BSTs)."><meta property="og:type" content="article"><meta property="og:url" content="/introduction-to-isolation-forests.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2023-05-28T11:45:56+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Introduction to Isolation Forests"><meta name=twitter:description content="Isolation Forests (IFs), presented in Liu1 et. al (2012), are a popular algorithm used for outlier classification. In a very simplified way, the method consists of building an ensemble of Isolation Trees (ITs) for a given data set and observations are deemed anomalies if they have short adjusted average path lengths on the ITs.
ITs, which will be covered shortly, have several properties in common with a fundamental data structure: the Binary Search Tree (BSTs)."><link rel=stylesheet href=/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=images/favicon.ico></head><body class="max-width mx-auto px3 ltr" x-data="{currentHeading: undefined}"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></span><br><div id=share style=display:none></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#isolation-trees :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#isolation-trees' }">Isolation Trees</a></li></ul></nav></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Introduction to Isolation Forests</h1><div class=meta><div class=postdate>Updated <time datetime="2023-05-28 11:45:56 +0100 BST" itemprop=datePublished>2023-05-28</time>
<span class=commit-hash>(<a href=/log/index.html#1454e0a>1454e0a</a>)</span></div></div></header><div class=content itemprop=articleBody><p><em>Isolation Forests</em> (IFs), presented in Liu<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> et. al (2012), are a popular algorithm used for outlier classification. In a very simplified way, the method consists of building an ensemble of
<em>Isolation Trees</em> (ITs) for a given data set and observations are deemed anomalies if they have short adjusted average path lengths on the ITs.</p><p>ITs, which will be covered shortly, have several properties in common with a fundamental data structure: the <a href=https://en.wikipedia.org/wiki/Binary_search_tree>Binary Search Tree</a> (BSTs). In a very simplified way, BSTs are a special instance of tree structures where keys are kept in such an order that a node search is performed by iteratively (or recursively) choosing a left or right branch based on a quantitative comparison (<em>e.g.</em> lesser or greater). Node insertion is performed by doing a tree search, using the method described previously, until reaching an <em>external node</em>, where the new node will be inserted. This allows for efficient node searches since, on average, half the tree will not be visited. To illustrate this assume the values $x=[1, 10, 2, 4, 3, 5, 26, 9, 7, 54]$ and the respective insertion on a BST. The intermediate steps would then be as shown below.</p><figure><img src=/assets/bst_steps.png alt=bst_steps.png></figure><p>One of the properties of BSTs is that, with randomly generated data, the path between the root node and the outliers will typically be shorter. We can see from the illustration below that, with our example data, the path length for (say) 7 is twice the length than for the suspicious value of 54. This property will play an important role in the IF algorithm, as we will see further on.</p><figure><img src=/assets/bst_path_length.png alt=bst_path_length.png></figure><h2 id=isolation-trees x-intersect="currentHeading = '#isolation-trees'">Isolation Trees</h2><p>Since ITs are the fundamental component of IFs, we will start by describing their building process. We start by defining $t$ as the number of trees in the IF, $\mathcal{D}$ as the training data (contained in an $n$-dimensional feature space, $\mathcal{D} \subset \mathbb{R}^n$) and $\psi$ as the subsampling size. The building of a IT consists then in recursively partitioning the data $\mathcal{D}$ by sampling (without replacement) a subsample $\mathcal{D}^{\prime}$ of size $\psi$. We then build an isolation tree $\mathcal{T}^{\prime}$ with this subsample (in order to later add it to the isolation forest $\mathcal{F}$) and the process is repeated $t$ times.</p><p>To build an isolation tree $\mathcal{T}^{\prime}$ from the subsample we proceed as follows: if the data subsample $\mathcal{D}^{\prime}$ is indivisible, a tree is returned containing a single <em>external node</em> corresponding to the feature dimensions, $n$. If it can be divided, a series of steps must be performed. Namely, if we consider $Q = \lbrace q_1,\dots,q_n\rbrace$ as the list of features in $\mathcal{D}^{\prime}$, we select a random feature $q \in Q$ and a random <em>split point</em> $p$ such that</p><p>$$
\min(q) &lt; p &lt; \max(q), \qquad q \in Q.
$$</p><p>Based on the cut-off point $p$, we filter the features into a BST’s left and right nodes according to</p><p>$$
\mathcal{D}_l := \lbrace \mathcal{D}^{\prime} : q \in Q, q&lt;p\rbrace \
\mathcal{D}_r := \lbrace \mathcal{D}^{\prime} : q \in Q, q \geq p\rbrace,
$$</p><p>and return an <em>internal node</em> having an isolation tree with left and right nodes as respectively $\mathcal{D}_l$ and $\mathcal{D}_r$.</p><p>To illustrate this (and the general method of identifying anomalies in a two dimensional feature space, $x\in\mathbb{R}^2$) we will look at some simulated data and its processing. We start by simulating two clusters of data from a multivariate normal distribution, one centred in $x_a=[-10, 10]$ and another centred in $x_b=[10, 10]$, with a variance of $\Sigma=\text{diag}(2, 2)$, that is</p><p>$$
X_a \sim \mathcal{N}\left([-10, -10], \text{diag}(2, 2)\right) \
X_b \sim \mathcal{N}\left([10, 10], \text{diag}(2, 2)\right).
$$</p><p>The particular realisation of this simulation looks like this:</p><figure><img src=/assets/data.png alt=data.png></figure><p>Below we illustrate the building of a <em>single</em> IT (given the data), illustrating the feature split point $p$ and respective division of the feature list into <em>left</em> or <em>right</em> IT nodes. The process is conducted recursively until the feature list is no longer divisible. As mentioned previously, this process, the creation of an IT, is repeated $t$ times in order to create the IF.</p><figure><img src=/assets/split.mp4 alt=split.mp4></figure><p>In order to perform anomaly detection (<em>e.g.</em> observation scoring) we will then use the IT equivalent of the BST unsuccessful search heuristics. An external node termination in an IT is equivalent to a BST unsuccessful search. Given an observation $x$, our goal is then to calculate the score for this observation, given our defined subsampling size, that is, $s(x,\psi)$.</p><p>This technique amounts to partitioning the feature space randomly until feature points are “isolated”. Intuitively, points in high density regions will need more partitioning steps, whereas anomalies (by definition away from high density regions) will need fewer splits. Since the building of the ITs is performed in a randomised fashion and using a subsample of the data, this density predictor can be average over a number of ITs, the <em>Isolation Forest</em>.</p><p>Intuitively, this could be done by calculating the average path length for our $\mathcal{T}n, n=1,\dots,t$ ITs, $\overline{h}(x)$.
However, as pointed in Liu<sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <em>et. al</em> (2012), a problem with calculating this is that maximum possible height of each $\mathcal{T}_n$ grows as $\mathcal{O}(\log(\psi))$. To compare $h(x)$ given different subsampling sizes, a normalisation factor, $c(\psi)$ must be established. This can be calculated by</p><p>$$
c(\psi) = \begin{cases}
2H(\psi-1)-2\frac{\psi-1}{n},\text{if}\ \psi >2,\
1, \text{if}\ \psi=2,\
0, \text{otherwise},
\end{cases}
$$</p><p>where $H(i)$ is the harmonic number estimated by $H(i)\approx\log(i) + e$.</p><p>Denoting $h_{max}$ as the tree height limit and e as the <em>current path length</em>, initialised as $e=0$ we can then calculate $h(x)$ recursively as:</p><p>$$
h(x,\mathcal{T},h_{max},e) = \begin{cases}
h(x,\mathcal{T}<em>{n,left},h</em>{max},e+1) \text{if}\ x_a &lt; q_{\mathcal{T}} \
h(x,\mathcal{T}<em>{n,right},h</em>{max},e+1) \text{if}\ x_a \geq q_{\mathcal{T}} \
e+c(\mathcal{T_{n,s}}) \text{if}\ \mathcal{T} \text{is a terminal node or}\ e \geq h_{max}.
\end{cases}
$$</p><p>Given these quantities we can then, finally, calculate the anomaly score, $s$ as</p><p>$$
s(x,\psi) = 2^{-\frac{\text{E}[h(x)]}{c(\psi)}}
$$</p><p>with $\text{E}[h(x)]$ being the average $h(x)$ for a collection of ITs.</p><ul><li>Parameters</li></ul><p>As mentioned in Liu<sup id=fnref2:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <em>et. al</em> (2012), the empirical subsampling size $\psi=2^8$ is typically enough to perform anomaly detection in a wide range of data. Regarding the number of trees, $t$ no considerable accuracy gain is usually observed with $t>100$. In the plots below, we can see the score calculation for two point in our data, namely an outlier ($x_o=[3.10, -12.69])$ and a normal observation ($x_n=[8.65, 9.71]$) with a varying number of trees and $\psi=2^8$ (<em>left</em>) and a varying subsample size and $t=100$ (<em>right</em>). We can see that the score value stabilised quite early on when using $\psi=2^8$ and that very low subsampling sizes can lead to problems when classifying anomalies.</p><figure><img src=/assets/avg_score.png alt=avg_score.png></figure><p>Now that we know how to implement an IF algorithm and calculate an anomaly score, we will try to visualise the anomaly score distribution in the vicinity of the simulated data. To do so, we simply create a two dimensional lattice enclosing our data an iteratively calculate $s(., \psi)$. The result is show below:</p><figure><img src=/assets/score_field.png alt=score_field.png></figure><p>The above steps fully define a naive isolation forest algorithm, which when applied to the previously simulated data, result in 88% of the anomalies being correctly identified.</p><figure><img src=/assets/detection.png alt=detection.png></figure><p>Thanks for reading! If you have any questions or comments, please let me know on <a href=https://mastodon.social/@ruivieira>Mastodon</a> or <a href=https://twitter.com/ruimvieira>Twitter</a>.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Liu, F. T., Ting, K. M., & Zhou, Z. (2012). Isolation-based anomaly detection. ACM Transactions on Knowledge Discovery from Data (TKDD), 6(1), 1–39.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#isolation-trees>Isolation Trees</a></li></ul></nav></div><div id=share-footer style=display:none></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2023 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/css/fa.min.css><script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/mark.min.js></script>
<script src=/js/main.js></script></html>