<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script type=module src=/js/deeplinks/deeplinks.js></script>
<link rel=preload href=/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/prociono/Prociono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>OOB score in random forests Â· Rui Vieira</title><link rel=canonical href=/oob-score-in-random-forests.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="OOB score in random forests"><meta property="og:description" content="In the Random Forest algorithm, we build a decision tree (DT) based on a certain training dataset. This tree will be split in order to minimise some criteria function.
However, it is not desirable that individual DTs get too large with too many splits, so a common approach is to train each tree with a subset of the training data (sampled with replacement). This will ensure that individual tree maintain a manageable size, while the variance of the tree ensemble is reduced and the overall bias is not altered."><meta property="og:type" content="article"><meta property="og:url" content="/oob-score-in-random-forests.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2022-07-01T10:49:58+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="OOB score in random forests"><meta name=twitter:description content="In the Random Forest algorithm, we build a decision tree (DT) based on a certain training dataset. This tree will be split in order to minimise some criteria function.
However, it is not desirable that individual DTs get too large with too many splits, so a common approach is to train each tree with a subset of the training data (sampled with replacement). This will ensure that individual tree maintain a manageable size, while the variance of the tree ensemble is reduced and the overall bias is not altered."><link rel=stylesheet href=/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=images/favicon.ico></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick="$('html, body').animate({scrollTop:0},'fast')" style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=%2foob-score-in-random-forests.html" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=%2foob-score-in-random-forests.html&text=OOB%20score%20in%20random%20forests" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=%2foob-score-in-random-forests.html&is_video=false&description=OOB%20score%20in%20random%20forests" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=OOB%20score%20in%20random%20forests&body=Check out this article: %2foob-score-in-random-forests.html" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=%2foob-score-in-random-forests.html&name=OOB%20score%20in%20random%20forests&description=In%20the%20Random%20Forest%20algorithm%2c%20we%20build%20a%20decision%20tree%20%28DT%29%20based%20on%20a%20certain%20training%20dataset.%20This%20tree%20will%20be%20split%20in%20order%20to%20minimise%20some%20criteria%20function.%0aHowever%2c%20it%20is%20not%20desirable%20that%20individual%20DTs%20get%20too%20large%20with%20too%20many%20splits%2c%20so%20a%20common%20approach%20is%20to%20train%20each%20tree%20with%20a%20subset%20of%20the%20training%20data%20%28sampled%20with%20replacement%29.%20This%20will%20ensure%20that%20individual%20tree%20maintain%20a%20manageable%20size%2c%20while%20the%20variance%20of%20the%20tree%20ensemble%20is%20reduced%20and%20the%20overall%20bias%20is%20not%20altered." aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=%2foob-score-in-random-forests.html&t=OOB%20score%20in%20random%20forests" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><h4>Contents</h4><nav id=TableOfContents></nav><h4>Related</h4><nav><ul><li class="header-post toc"><span class=backlink-count>1</span>
<a href=/optimising-random-forest-hyperparamaters.html>Optimising random forest hyperparamaters</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">OOB score in random forests</h1><div class=meta><div class=postdate>Updated <time datetime="2022-07-01 10:49:58 +0100 BST" itemprop=datePublished>2022-07-01</time>
<span class=commit-hash>(e7bb158)</span></div></div></header><div class=content itemprop=articleBody><p>In the <a href>Random Forest</a> algorithm, we build a decision tree (DT) based on a certain training dataset. This tree will be split in order to minimise some criteria function.</p><p>However, it is not desirable that individual DTs get too large with too many splits, so a common approach is to train each tree with a <em>subset of the training data</em> (sampled with replacement). This will ensure that individual tree maintain a manageable size, while the variance of the tree ensemble is reduced and the overall bias is not altered.</p><p>This <em>training subset</em> is usually called the <strong>bootstrap samples</strong>. In the image below, we can see an illustration of the sampling with replacement.</p></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=%2foob-score-in-random-forests.html" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=%2foob-score-in-random-forests.html&text=OOB%20score%20in%20random%20forests" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=%2foob-score-in-random-forests.html&is_video=false&description=OOB%20score%20in%20random%20forests" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=OOB%20score%20in%20random%20forests&body=Check out this article: %2foob-score-in-random-forests.html" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=%2foob-score-in-random-forests.html&title=OOB%20score%20in%20random%20forests" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=%2foob-score-in-random-forests.html&name=OOB%20score%20in%20random%20forests&description=In%20the%20Random%20Forest%20algorithm%2c%20we%20build%20a%20decision%20tree%20%28DT%29%20based%20on%20a%20certain%20training%20dataset.%20This%20tree%20will%20be%20split%20in%20order%20to%20minimise%20some%20criteria%20function.%0aHowever%2c%20it%20is%20not%20desirable%20that%20individual%20DTs%20get%20too%20large%20with%20too%20many%20splits%2c%20so%20a%20common%20approach%20is%20to%20train%20each%20tree%20with%20a%20subset%20of%20the%20training%20data%20%28sampled%20with%20replacement%29.%20This%20will%20ensure%20that%20individual%20tree%20maintain%20a%20manageable%20size%2c%20while%20the%20variance%20of%20the%20tree%20ensemble%20is%20reduced%20and%20the%20overall%20bias%20is%20not%20altered." aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=%2foob-score-in-random-forests.html&t=OOB%20score%20in%20random%20forests" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick="return $('#nav-footer').toggle(),!1" aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick="return $('#toc-footer').toggle(),!1" aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick="return $('#share-footer').toggle(),!1" aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast')" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2022 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/css/fa.min.css><script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/mark.min.js></script>
<script src=/js/main.js></script></html>