<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script><script src=https://unpkg.com/@alpinejs/intersect@3.x.x/dist/cdn.min.js></script><script src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script><script type=module src=https://ruivieira.dev/js/deeplinks/deeplinks.js></script><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=https://ruivieira.dev/fonts/vollkorn/Vollkorn-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=https://ruivieira.dev/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Serving models with Seldon Â· Rui Vieira</title>
<link rel=canonical href=https://ruivieira.dev/serving-models-with-seldon.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Serving models with Seldon"><meta property="og:description" content="Deploying machine learning models in production comes with several requirements. We must manage the model lifecycle. We need reproducibility and typically use containerised workflows.
Seldon1 is a tool which aims at providing a production workflow for machine learning models, allowing to build model serving containers which expose well-defined APIs.
In this post, I&rsquo;ll show how to create a simple model and how to deploy it with Seldon. The model is a customer segmentation one."><meta property="og:type" content="article"><meta property="og:url" content="https://ruivieira.dev/serving-models-with-seldon.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2024-02-10T16:17:19+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Serving models with Seldon"><meta name=twitter:description content="Deploying machine learning models in production comes with several requirements. We must manage the model lifecycle. We need reproducibility and typically use containerised workflows.
Seldon1 is a tool which aims at providing a production workflow for machine learning models, allowing to build model serving containers which expose well-defined APIs.
In this post, I&rsquo;ll show how to create a simple model and how to deploy it with Seldon. The model is a customer segmentation one."><link rel=stylesheet href=https://ruivieira.dev/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://ruivieira.dev/images/favicon.ico></head><body class="max-width mx-auto px3 ltr" x-data="{currentHeading: undefined}"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></span><br><div id=share style=display:none></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#create-data :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#create-data' }">Create data</a></li><li><a href=#train-model :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#train-model' }">Train model</a></li><li><a href=#deploy-model :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#deploy-model' }">Deploy model</a></li><li><a href=#simple-model :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#simple-model' }">Simple model</a></li><li><a href=#with-metrics :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#with-metrics' }">With metrics</a></li></ul></nav><h4>Related</h4><nav><ul><li class="header-post toc"><span class=backlink-count>1</span>
<a href=https://ruivieira.dev/model-serving.html>Model serving</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Serving models with Seldon</h1><div class=meta><div class=postdate>Updated <time datetime="2024-02-10 16:17:19 +0000 GMT" itemprop=datePublished>2024-02-10</time>
<span class=commit-hash>(<a href=https://ruivieira.dev/log/index.html#e4a50cc>e4a50cc</a>)</span></div></div></header><div class=content itemprop=articleBody><p>Deploying machine learning models in production comes with several requirements.
We must manage the model lifecycle. We need reproducibility and typically use containerised workflows.</p><p><a href>Seldon</a><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> is a tool which aims at providing a production workflow for <a href=https://ruivieira.dev/machine-learning.html>machine learning</a> models, allowing to build model serving containers which expose well-defined APIs.</p><p>In this post, I&rsquo;ll show how to create a simple model and how to deploy it with Seldon. The model is a customer segmentation one. The goal is to classify a customer according to a segment (<code>0</code>, <code>1</code> or <code>2</code>), according to its age, income, whether they engaged with previous campaigns and the campaign type.</p><p>Once we train the model, we deploy it with Seldon in a container orchestration
platform such as <a href=https://ruivieira.dev/kubernetes.html>Kubernetes</a><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> and <a href=https://ruivieira.dev/openshift.html>OpenShift</a><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>.</p><h2 id=create-data x-intersect="currentHeading = '#create-data'">Create data</h2><p>We use the Python&rsquo;s <a href=https://ruivieira.dev/scikit-learn.html>Scikit-learn</a><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> to train our model.
However, we must first simulate some data to train it.
We start by simulating the users age ($a$) and income ($c$). We assume income is correlated with age.</p><p>$$
\begin{aligned}
c|a &\sim \mathcal{N}\left(a + 20, 100\right) \\
a|k &\sim \mathcal{U}\left(A_k, B_k\right),\quad A=\left\lbrace16, 25, 50, 61\right\rbrace,B=\left\lbrace24, 49, 60, 90\right\rbrace \\
k &\sim \mathcal{M}\left(4, \left\lbrace 0.15, 0.4, 0.2, 0.25\right\rbrace\right)
\end{aligned}
$$</p><figure><img src=https://ruivieira.dev/pages/site/images/seldon_segments.png alt=seldon_segments.png loading=lazy></figure><p>Let&rsquo;s assume we have eight distinct events ($e=\left(0, 1, \dots, 7\right)$). We sample them from a multinomial
distribution and also assume that two different age bands have different distributions, just to add some variation.</p><p>$$
e = \begin{cases} \mathcal{M}\left(7, \left\lbrace 0.026, 0.195, 0.156, 0.208, 0.130, 0.205, 0.078 \right\rbrace\right) & \text{if}\ a &lt; 50 \\
\mathcal{M}\left(7, \left\lbrace 0.052, 0.143, 0.169, 0.182, 0.164, 0.182, 0.104 \right\rbrace\right) & \text{if}\ a \geq 50
\end{cases}
$$</p><figure><img src=https://ruivieira.dev/pages/site/images/seldon_hist_event_income.png alt=seldon_hist_event_income.png loading=lazy></figure><p>The responses are calculated as <code>0</code> or <code>1</code>, representing &ldquo;true&rdquo; or &ldquo;false&rdquo;, and sampled from Bernoulli
distributions, with different distributions depending on the event, again just to add some variation.</p><p>$$
r = \begin{cases}
\text{Bernoulli}\left(0.6\right) & \text{if}\ e \in \left(2, 3, 4, 6\right) \\
\text{Bernoulli}\left(0.4\right) & \text{if}\ e \in \left(1, 5, 7\right)
\end{cases}
$$</p><p>To predict the response of a customer, we use a logistic model, with coefficients $\beta_{age}=-0.0004$ and $\beta_{income}=0.0001$. For the customer level, we use a negative binomial model with coefficients $\beta_{age}=-0.0233$ and $\beta_{income}=0.0054$.
This results in the following distribution of customer levels:</p><figure><img src=https://ruivieira.dev/pages/site/images/seldon_level.png alt=seldon_level.png loading=lazy></figure><p>Finally, we create the response according to negative binomial model with coefficients $\beta_{level}=0.1862$ and $\beta_{response}=0.2076$. We get the following segments, stratified by age and income:</p><figure><img src=https://ruivieira.dev/pages/site/images/seldon_segments.png alt=seldon_segments.png loading=lazy></figure><h2 id=train-model x-intersect="currentHeading = '#train-model'">Train model</h2><p>Now that we have our simulated data, we can train a model.
Generally, it is straightforward to train model data when in <code>pandas</code> data frame format.
Let&rsquo;s proceed with creating a data frame with the data we&rsquo;ve just generated:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>pandas</span> <span style=font-weight:700>as</span> <span style=color:#555>pd</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;age&#34;</span>: age,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;income&#34;</span>: income,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;class&#34;</span>: _class,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;response&#34;</span>: response,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;segment&#34;</span>: segment,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;events&#34;</span>: events,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data)
</span></span></code></pre></div><p>We now create the training and testing datasets. The first thing is to define the classifier&rsquo;s <code>inputs</code> and <code>outputs</code> and then splitting each of them into training and testing. Here I have used a split of 60%/40% for training and testing respectively.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.model_selection</span> <span style=font-weight:700>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cols <span style=font-weight:700>=</span> [<span style=color:#b84>&#34;age&#34;</span>, <span style=color:#b84>&#34;income&#34;</span>, <span style=color:#b84>&#34;response&#34;</span>, <span style=color:#b84>&#34;events&#34;</span>]
</span></span><span style=display:flex><span>inputs <span style=font-weight:700>=</span> df[cols]
</span></span><span style=display:flex><span>outputs <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;segment&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># split dataset</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=font-weight:700>=</span> train_test_split(
</span></span><span style=display:flex><span>    inputs, outputs, test_size<span style=font-weight:700>=</span><span style=color:#099>0.4</span>, random_state<span style=font-weight:700>=</span><span style=color:#099>23</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>We use a <a href=https://ruivieira.dev/random-forest.html>Random Forest</a> classifier as the underlying algorithm for our model.
These are available in <code>sciki-learn</code> with the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html><code>RandomForestClassifier</code></a> class.
However, <code>scikit-learn</code> does not support categorical variables out of the box<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>.
To deal with them, we build a <a href=https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html><code>Pipeline</code></a>, which allows to chain multiple transformations to our data, including a categorical variable processor, such as <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html><code>OrdinalEncoder</code></a><sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.
We use <a href=https://github.com/scikit-learn-contrib/sklearn-pandas><code>DataFrameMapper</code></a> to apply the encoder to the <code>response</code> and <code>events</code> columns and leave the remaining unchanged.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.ensemble</span> <span style=font-weight:700>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn</span> <span style=font-weight:700>import</span> preprocessing
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.pipeline</span> <span style=font-weight:700>import</span> Pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>build_RF_pipeline</span>(inputs, outputs, rf<span style=font-weight:700>=</span><span style=font-weight:700>None</span>):
</span></span><span style=display:flex><span>    <span style=font-weight:700>if</span> <span style=font-weight:700>not</span> rf:
</span></span><span style=display:flex><span>        rf <span style=font-weight:700>=</span> RandomForestClassifier()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    pipeline <span style=font-weight:700>=</span> Pipeline(
</span></span><span style=display:flex><span>        [
</span></span><span style=display:flex><span>            (
</span></span><span style=display:flex><span>                <span style=color:#b84>&#34;mapper&#34;</span>,
</span></span><span style=display:flex><span>                DataFrameMapper(
</span></span><span style=display:flex><span>                    [
</span></span><span style=display:flex><span>                        ([<span style=color:#b84>&#34;response&#34;</span>, <span style=color:#b84>&#34;events&#34;</span>], preprocessing<span style=font-weight:700>.</span>OrdinalEncoder()),
</span></span><span style=display:flex><span>                        ([<span style=color:#b84>&#34;age&#34;</span>, <span style=color:#b84>&#34;income&#34;</span>], <span style=font-weight:700>None</span>),
</span></span><span style=display:flex><span>                    ]
</span></span><span style=display:flex><span>                ),
</span></span><span style=display:flex><span>            ),
</span></span><span style=display:flex><span>            (<span style=color:#b84>&#34;classifier&#34;</span>, rf),
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    pipeline<span style=font-weight:700>.</span>fit(inputs, outputs)
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> pipeline
</span></span></code></pre></div><p>The actual training involves a simple hyper-parameter estimation using
<a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html><code>RandomizedSearchCV</code></a>. This method performs a type of parameter grid search but restricting the search to only the specified values. For the scope of this post, it is not necessary to perform an exhaustive hyperparameter estimation.
The <code>RF_estimation</code> function returns the best-fitted model after searching with the test dataset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>RF_estimation</span>(
</span></span><span style=display:flex><span>    inputs,
</span></span><span style=display:flex><span>    outputs,
</span></span><span style=display:flex><span>    estimator_steps<span style=font-weight:700>=</span><span style=color:#099>10</span>,
</span></span><span style=display:flex><span>    depth_steps<span style=font-weight:700>=</span><span style=color:#099>10</span>,
</span></span><span style=display:flex><span>    min_samples_split<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    min_samples_leaf<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>):
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># hyper-parameter estimation</span>
</span></span><span style=display:flex><span>    n_estimators <span style=font-weight:700>=</span> [
</span></span><span style=display:flex><span>        <span style=color:#999>int</span>(x) <span style=font-weight:700>for</span> x <span style=font-weight:700>in</span> np<span style=font-weight:700>.</span>linspace(start<span style=font-weight:700>=</span><span style=color:#099>50</span>, stop<span style=font-weight:700>=</span><span style=color:#099>100</span>, num<span style=font-weight:700>=</span>estimator_steps)
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>    max_depth <span style=font-weight:700>=</span> [<span style=color:#999>int</span>(x) <span style=font-weight:700>for</span> x <span style=font-weight:700>in</span> np<span style=font-weight:700>.</span>linspace(<span style=color:#099>3</span>, <span style=color:#099>10</span>, num<span style=font-weight:700>=</span>depth_steps)]
</span></span><span style=display:flex><span>    max_depth<span style=font-weight:700>.</span>append(<span style=font-weight:700>None</span>)
</span></span><span style=display:flex><span>    <span style=font-weight:700>if</span> <span style=font-weight:700>not</span> min_samples_split:
</span></span><span style=display:flex><span>        min_samples_split <span style=font-weight:700>=</span> [<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>4</span>]
</span></span><span style=display:flex><span>    <span style=font-weight:700>if</span> <span style=font-weight:700>not</span> min_samples_leaf:
</span></span><span style=display:flex><span>        min_samples_leaf <span style=font-weight:700>=</span> [<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>4</span>]
</span></span><span style=display:flex><span>    bootstrap <span style=font-weight:700>=</span> [<span style=font-weight:700>True</span>, <span style=font-weight:700>False</span>]
</span></span><span style=display:flex><span>    random_grid <span style=font-weight:700>=</span> {
</span></span><span style=display:flex><span>        <span style=color:#b84>&#34;n_estimators&#34;</span>: n_estimators,
</span></span><span style=display:flex><span>        <span style=color:#b84>&#34;max_depth&#34;</span>: max_depth,
</span></span><span style=display:flex><span>        <span style=color:#b84>&#34;min_samples_split&#34;</span>: min_samples_split,
</span></span><span style=display:flex><span>        <span style=color:#b84>&#34;min_samples_leaf&#34;</span>: min_samples_leaf,
</span></span><span style=display:flex><span>        <span style=color:#b84>&#34;bootstrap&#34;</span>: bootstrap,
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rf_random <span style=font-weight:700>=</span> RandomizedSearchCV(
</span></span><span style=display:flex><span>        estimator<span style=font-weight:700>=</span>RandomForestClassifier(),
</span></span><span style=display:flex><span>        param_distributions<span style=font-weight:700>=</span>random_grid,
</span></span><span style=display:flex><span>        n_iter<span style=font-weight:700>=</span><span style=color:#099>100</span>,
</span></span><span style=display:flex><span>        scoring<span style=font-weight:700>=</span><span style=color:#b84>&#34;neg_mean_absolute_error&#34;</span>,
</span></span><span style=display:flex><span>        cv<span style=font-weight:700>=</span><span style=color:#099>3</span>,
</span></span><span style=display:flex><span>        verbose<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        random_state<span style=font-weight:700>=</span><span style=color:#099>42</span>,
</span></span><span style=display:flex><span>        n_jobs<span style=font-weight:700>=-</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    rf_random<span style=font-weight:700>.</span>fit(inputs, outputs)
</span></span><span style=display:flex><span>    best_random <span style=font-weight:700>=</span> rf_random<span style=font-weight:700>.</span>best_estimator_
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> best_random
</span></span></code></pre></div><p>After applying the parameter estimation, we take the best scoring model and calculate the MSE. Unsurprisingly (given the simple model and simulated data), we get a very good fit.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>rf_predictions <span style=font-weight:700>=</span> random_forest_pipeline<span style=font-weight:700>.</span>predict(X_test)
</span></span><span style=display:flex><span><span style=color:#999>print</span>(<span style=color:#b84>f</span><span style=color:#b84>&#34;MSE: </span><span style=color:#b84>{</span>random_forest_pipeline<span style=font-weight:700>.</span>score(X_test, y_test)<span style=font-weight:700>*</span><span style=color:#099>100</span><span style=color:#b84>}</span><span style=color:#b84>%&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># MSE: 99.95%</span>
</span></span></code></pre></div><p>The final step is serialising the model. Serialisation is necessary since we only serve the pre-trained model.
To do so, we use the <a href=https://github.com/joblib/joblib><code>joblib</code></a> library and save the model to a <code>model.pkl</code> file.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>joblib</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># save mode in filesystem</span>
</span></span><span style=display:flex><span>joblib<span style=font-weight:700>.</span>dump(random_forest_pipeline, <span style=color:#b84>&#34;model.pkl&#34;</span>)
</span></span></code></pre></div><h2 id=deploy-model x-intersect="currentHeading = '#deploy-model'">Deploy model</h2><p>It is important to note that we don&rsquo;t need the model training code included in the Seldon server. The purpose of Seldon is not to <em>train</em> models, but to <em>deploy</em> them and manage their lifecycle.
This workflow means that a typical Seldon deployment would only include the prediction endpoint implementation and a serialised model.
This provision is made by firstly create a <em>wrapper</em> for our model which implements the Seldon endpoints.</p><h3 id=simple-model x-intersect="currentHeading = '#simple-model'">Simple model</h3><p>We create a Python script called <code>Model.py</code> <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>.
The primary prediction endpoint uses the following signature:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>predict</span>(self, X: np<span style=font-weight:700>.</span>ndarray, names: Iterable[<span style=color:#999>str</span>], meta: Dict <span style=font-weight:700>=</span> <span style=font-weight:700>None</span>)
</span></span></code></pre></div><p>The wrapper is straightforward, in this example.
We use the <code>joblib</code> library again, to load the serialised model <code>model.pkl</code>, and then pass through any JSON payload as inputs (<code>X</code>) to the model to get a prediction as well as using Python&rsquo;s default <a href=https://docs.python.org/3/library/logging.html>logging</a> to provide some feedback.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>joblib</span>
</span></span><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>logging</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>class</span> <span style=color:#458;font-weight:700>Model</span>(<span style=color:#999>object</span>):
</span></span><span style=display:flex><span>    <span style=font-weight:700>def</span> __init__(self):
</span></span><span style=display:flex><span>        logger<span style=font-weight:700>.</span>info(<span style=color:#b84>&#34;Initializing.&#34;</span>)
</span></span><span style=display:flex><span>        logger<span style=font-weight:700>.</span>info(<span style=color:#b84>&#34;Loading model.&#34;</span>)
</span></span><span style=display:flex><span>        self<span style=font-weight:700>.</span>model <span style=font-weight:700>=</span> joblib<span style=font-weight:700>.</span>load(<span style=color:#b84>&#34;model.pkl&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>predict</span>(self, X, features_names):
</span></span><span style=display:flex><span>        <span style=font-weight:700>return</span> self<span style=font-weight:700>.</span>model<span style=font-weight:700>.</span>predict_proba(X)
</span></span></code></pre></div><p>We now build the model using the <code>s2i</code> (<a href=https://github.com/openshift/source-to-image>source-to-image</a>).
As the name implies, <code>s2i</code>&rsquo;s allow to create a container image from source code, taking care of any necessary intermediate steps.
Seldon support several types of builds (such as Python, R and Java)<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><p>Typically <code>s2i</code>&rsquo;s rely on certain conventions (over configuration) on your application structure. A requirement when building a Seldon model using its <code>s2i</code> is to provide some specific environment variables. These are usually stored in a file located in <code>$REPO/.s2i/environment</code>. For instance, for this model we use:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-properties data-lang=properties><span style=display:flex><span><span style=color:teal>MODEL_NAME</span><span style=font-weight:700>=</span><span style=color:#b84>Model</span>
</span></span><span style=display:flex><span><span style=color:teal>API_TYPE</span><span style=font-weight:700>=</span><span style=color:#b84>REST</span>
</span></span><span style=display:flex><span><span style=color:teal>SERVICE_TYPE</span><span style=font-weight:700>=</span><span style=color:#b84>MODEL</span>
</span></span><span style=display:flex><span><span style=color:teal>PERSISTENCE</span><span style=font-weight:700>=</span><span style=color:#b84>0</span>
</span></span></code></pre></div><p>The <code>MODEL_NAME</code> corresponds to the script we&rsquo;ve created previously, <code>Model.py</code> and instructs Seldon to use it as the REST endpoint provider. <code>API_TYPE</code> defines the endpoint interface. We use the REST interface, other possibilities include gRPC, for instance.</p><figure><img src=https://ruivieira.dev/Excalidraw/Serving%20models%20with%20Seldon%20-%20diagram.excalidraw.svg alt="Serving models with Seldon - diagram.excalidraw.svg" loading=lazy></figure><p>To build the container image using the <code>s2i</code>, assuming you want an image named <code>$NAME</code> and tagged with <code>$TAG</code>, we simply need to run:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ s2i build <span style=color:teal>$REPO</span> <span style=color:#b84>\
</span></span></span><span style=display:flex><span><span style=color:#b84></span>  seldonio/seldon-core-s2i-python36:0.18 <span style=color:#b84>\
</span></span></span><span style=display:flex><span><span style=color:#b84></span>  <span style=color:teal>$NAME</span>:<span style=color:teal>$TAG</span>
</span></span></code></pre></div><p>You can provide the location of your source code either by specifying a remote Git repository or by passing a local one.
Once the container image builds, you can now run it using, for instance:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker run -i --rm -p 5000:5000 <span style=color:teal>$NAME</span>:<span style=color:teal>$TAG</span>
</span></span></code></pre></div><p>Let&rsquo;s get a prediction from the model:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ curl --header <span style=color:#b84>&#34;Content-Type: application/json&#34;</span> <span style=color:#b84>\
</span></span></span><span style=display:flex><span><span style=color:#b84></span>  --request POST <span style=color:#b84>\
</span></span></span><span style=display:flex><span><span style=color:#b84></span>  --data <span style=color:#b84>&#39;{&#34;data&#34;:{&#34;ndarray&#34;:[34.0, 100.0, 1, 2]()}}&#39;</span> <span style=color:#b84>\
</span></span></span><span style=display:flex><span><span style=color:#b84></span>  http://localhost:5000/predict
</span></span></code></pre></div><p>This will return a prediction:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:navy>&#34;data&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:navy>&#34;names&#34;</span>: [<span style=color:#b84>&#34;t:0&#34;</span>,<span style=color:#b84>&#34;t:1&#34;</span>,<span style=color:#b84>&#34;t:2&#34;</span>],
</span></span><span style=display:flex><span>        <span style=color:navy>&#34;ndarray&#34;</span>: [<span style=color:#099>0.0</span>,<span style=color:#099>0.9980208571211083</span>,<span style=color:#099>0.00197914287889168</span>]},
</span></span><span style=display:flex><span>    <span style=color:navy>&#34;meta&#34;</span>: {}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This response corresponds to the probability of each segment (<code>0</code>, <code>1</code> and <code>2</code>), respectively.
We can see that a customer with this profile is classified as a segment <code>1</code> with an associated probability of 99.8%.</p><h3 id=with-metrics x-intersect="currentHeading = '#with-metrics'">With metrics</h3><p>Seldon provides basic metrics by default, covering service, predictor and model name, version and image. However, you can directly add custom metrics. Going back to our <code>Model</code> wrapper class, we add a new method called <code>metrics</code> which returns custom metrics. The metrics are compatible with Prometheus and, therefore, the metric type should be familiar if you have dealt with Prometheus before. These include, for instance:</p><ul><li>Counters</li><li>Gauges</li><li>Timers</li></ul><p>Let&rsquo;s add to the wrapper:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>joblib</span>
</span></span><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>logging</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>class</span> <span style=color:#458;font-weight:700>Model</span>(<span style=color:#999>object</span>):
</span></span><span style=display:flex><span>    <span style=font-weight:700>def</span> __init__(self):
</span></span><span style=display:flex><span>        logger<span style=font-weight:700>.</span>info(<span style=color:#b84>&#34;Initializing.&#34;</span>)
</span></span><span style=display:flex><span>        logger<span style=font-weight:700>.</span>info(<span style=color:#b84>&#34;Loading model.&#34;</span>)
</span></span><span style=display:flex><span>        self<span style=font-weight:700>.</span>model <span style=font-weight:700>=</span> joblib<span style=font-weight:700>.</span>load(<span style=color:#b84>&#34;model.pkl&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>predict</span>(self, X, features_names):
</span></span><span style=display:flex><span>        <span style=font-weight:700>return</span> self<span style=font-weight:700>.</span>model<span style=font-weight:700>.</span>predict_proba(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># new custom metrics endpoint</span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>metrics</span>(self):
</span></span><span style=display:flex><span>        <span style=font-weight:700>return</span> [
</span></span><span style=display:flex><span>            <span style=color:#998;font-style:italic># a counter which will increase by the given value</span>
</span></span><span style=display:flex><span>            {<span style=color:#b84>&#34;type&#34;</span>: <span style=color:#b84>&#34;COUNTER&#34;</span>, <span style=color:#b84>&#34;key&#34;</span>: <span style=color:#b84>&#34;mycounter&#34;</span>, <span style=color:#b84>&#34;value&#34;</span>: <span style=color:#099>1</span>},
</span></span><span style=display:flex><span>            <span style=color:#998;font-style:italic># a gauge which will be set to given value</span>
</span></span><span style=display:flex><span>            {<span style=color:#b84>&#34;type&#34;</span>: <span style=color:#b84>&#34;GAUGE&#34;</span>, <span style=color:#b84>&#34;key&#34;</span>: <span style=color:#b84>&#34;mygauge&#34;</span>, <span style=color:#b84>&#34;value&#34;</span>: <span style=color:#099>10</span>},
</span></span><span style=display:flex><span>            <span style=color:#998;font-style:italic># a timer which will add sum and count metrics - assumed millisecs</span>
</span></span><span style=display:flex><span>            {<span style=color:#b84>&#34;type&#34;</span>: <span style=color:#b84>&#34;TIMER&#34;</span>, <span style=color:#b84>&#34;key&#34;</span>: <span style=color:#b84>&#34;mytimer&#34;</span>, <span style=color:#b84>&#34;value&#34;</span>: <span style=color:#099>1.1</span>},
</span></span><span style=display:flex><span>        ]
</span></span></code></pre></div><p>If we now request a new prediction, as previously, we can see the custom metrics included in the model&rsquo;s response.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:navy>&#34;data&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:navy>&#34;names&#34;</span>: [<span style=color:#b84>&#34;t:0&#34;</span>,<span style=color:#b84>&#34;t:1&#34;</span>,<span style=color:#b84>&#34;t:2&#34;</span>],
</span></span><span style=display:flex><span>        <span style=color:navy>&#34;ndarray&#34;</span>:[<span style=color:#099>0.0</span>,<span style=color:#099>0.9980208571211083</span>,<span style=color:#099>0.00197914287889168</span>]},
</span></span><span style=display:flex><span>    <span style=color:navy>&#34;meta&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:navy>&#34;metrics&#34;</span>: [
</span></span><span style=display:flex><span>            {<span style=color:navy>&#34;key&#34;</span>:<span style=color:#b84>&#34;mycounter&#34;</span>,<span style=color:navy>&#34;type&#34;</span>:<span style=color:#b84>&#34;COUNTER&#34;</span>,<span style=color:navy>&#34;value&#34;</span>:<span style=color:#099>1</span>},
</span></span><span style=display:flex><span>            {<span style=color:navy>&#34;key&#34;</span>:<span style=color:#b84>&#34;mygauge&#34;</span>,<span style=color:navy>&#34;type&#34;</span>:<span style=color:#b84>&#34;GAUGE&#34;</span>,<span style=color:navy>&#34;value&#34;</span>:<span style=color:#099>10</span>},
</span></span><span style=display:flex><span>            {<span style=color:navy>&#34;key&#34;</span>:<span style=color:#b84>&#34;mytimer&#34;</span>,<span style=color:navy>&#34;type&#34;</span>:<span style=color:#b84>&#34;TIMER&#34;</span>,<span style=color:navy>&#34;value&#34;</span>:<span style=color:#099>1.1</span>}]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>These values are available via the Prometheus endpoint.</p><p>The model can also be easily deployed in a container platform, for instance, OpenShift. Assuming you are logged to a cluster and your image is a registry accessible by OpenShift, you can simply deploy it using:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ oc new-app <span style=color:teal>$NAME</span>:<span style=color:teal>$TAG</span>
</span></span></code></pre></div><p>I hope this was useful to you.
Happy coding!</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://github.com/SeldonIO/seldon-core>https://github.com/SeldonIO/seldon-core</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://kubernetes.io/>https://kubernetes.io/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://www.openshift.com/>https://www.openshift.com/</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://scikit-learn.org/stable/>https://scikit-learn.org/stable/</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>As of the time of writing.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>Other encoders are available in <code>scikit-learn</code>. I recommend you experiment with some of them.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>You can use any file name, as long as it&rsquo;s consistent with <code>.s2i/environment</code>, which we&rsquo;ll look at soon.&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p>More information can be found <a href=https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/s2i.html>here</a>.&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#create-data>Create data</a></li><li><a href=#train-model>Train model</a></li><li><a href=#deploy-model>Deploy model</a><ul><li><a href=#simple-model>Simple model</a></li><li><a href=#with-metrics>With metrics</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2024 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=https://ruivieira.dev/>Home</a></li><li><a href=https://ruivieira.dev/blog/>Blog</a></li><li><a href=https://ruivieira.dev/draw/>Drawings</a></li><li><a href=https://ruivieira.dev/map/>All pages</a></li><li><a href=https://ruivieira.dev/search.html>Search</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=https://ruivieira.dev/css/fa.min.css><script src=https://ruivieira.dev/js/jquery-3.6.0.min.js></script><script src=https://ruivieira.dev/js/mark.min.js></script><script src=https://ruivieira.dev/js/main.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>