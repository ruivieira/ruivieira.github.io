<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script src=https://unpkg.com/@alpinejs/intersect@3.x.x/dist/cdn.min.js></script>
<script src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script>
<script type=module src=/js/deeplinks/deeplinks.js></script>
<link rel=preload href=/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/prociono/Prociono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Synthetic Data Generation Â· Rui Vieira</title><link rel=canonical href=/synthetic-data-generation.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Synthetic Data Generation"><meta property="og:description" content="Generating synthetic dataSynthetic data will be used mainly for these scenarios:
Regression Classification Here we will mainly look at the methods provided by scikit-learn to generate synthetic datasets. For more advanced methods, such as using the SDV library please check the SDV page. It support methods such as Gaussian copulas, CTGAN and CopulaGAN.
Regression dataWhat does a regression consist of?
For this section we will mainly use scikit-learn&rsquo;s make_regression method."><meta property="og:type" content="article"><meta property="og:url" content="/synthetic-data-generation.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2023-01-15T15:53:40+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Synthetic Data Generation"><meta name=twitter:description content="Generating synthetic dataSynthetic data will be used mainly for these scenarios:
Regression Classification Here we will mainly look at the methods provided by scikit-learn to generate synthetic datasets. For more advanced methods, such as using the SDV library please check the SDV page. It support methods such as Gaussian copulas, CTGAN and CopulaGAN.
Regression dataWhat does a regression consist of?
For this section we will mainly use scikit-learn&rsquo;s make_regression method."><link rel=stylesheet href=/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=images/favicon.ico></head><body class="max-width mx-auto px3 ltr" x-data="{currentHeading: undefined}"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></span><br><div id=share style=display:none></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#generating-synthetic-data :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#generating-synthetic-data' }">Generating synthetic data</a></li><li><a href=#regression-data :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#regression-data' }">Regression data</a></li><li><a href=#changing-the-gaussian-noise-level :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#changing-the-gaussian-noise-level' }">Changing the Gaussian noise level</a></li><li><a href=#visualising-increasing-noise :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#visualising-increasing-noise' }">Visualising increasing noise</a></li><li><a href=#classification-data :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#classification-data' }">Classification data</a></li><li><a href=#cluster-separation :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#cluster-separation' }">Cluster separation</a></li><li><a href=#noise-level :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#noise-level' }">Noise level</a></li><li><a href=#separability :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#separability' }">Separability</a></li><li><a href=#anisotropic-data :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#anisotropic-data' }">Anisotropic data</a></li><li><a href=#concentric-clusters :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#concentric-clusters' }">Concentric clusters</a></li><li><a href=#adding-noise :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#adding-noise' }">Adding noise</a></li><li><a href=#moon-clusters :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#moon-clusters' }">Moon clusters</a></li><li><a href=#adding-noise :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#adding-noise' }">Adding noise</a></li><li><a href=#time-series-data :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#time-series-data' }">Time-series data</a></li><li><a href=#random-walk :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#random-walk' }">Random walk</a></li><li><a href=#simple-periodic :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#simple-periodic' }">Simple periodic</a></li><li><a href=#no-trend :class="{'toc-h4':true, 'toc-highlight': currentHeading == '#no-trend' }">No trend</a></li><li><a href=#trend :class="{'toc-h4':true, 'toc-highlight': currentHeading == '#trend' }">Trend</a></li><li><a href=#univariate-data :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#univariate-data' }">Univariate data</a></li></ul></nav><h4>Related</h4><nav><ul><li class="header-post toc"><span class=backlink-count>1</span>
<a href=/k-means-clustering.html>K-means clustering</a></li><li class="header-post toc"><span class=backlink-count>1</span>
<a href=/machine-learning.html>Machine learning</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Synthetic Data Generation</h1><div class=meta><div class=postdate>Updated <time datetime="2023-01-15 15:53:40 +0000 GMT" itemprop=datePublished>2023-01-15</time>
<span class=commit-hash>(<a href=/log/index.html#fe73f60>fe73f60</a>)</span></div></div></header><div class=content itemprop=articleBody><h2 id=generating-synthetic-data x-intersect="currentHeading = '#generating-synthetic-data'">Generating synthetic data</h2><p>Synthetic data will be used mainly for these scenarios:</p><ul><li>Regression</li><li>Classification</li></ul><p>Here we will mainly look at the methods provided by <code>scikit-learn</code> to generate synthetic datasets. For more advanced methods, such as using the SDV library please check the <a href=/synthetic-data-generation-with-sdv.html>SDV page</a>. It support methods such as <a href>Gaussian copulas</a>, <a href=/synthetic-data-with-sdv-and-ctgan.html>CTGAN</a> and <a href=/synthetic-data-with-svd-and-copulagan.html>CopulaGAN</a>.</p><h2 id=regression-data x-intersect="currentHeading = '#regression-data'">Regression data</h2><p>What does a regression consist of?</p><p>For this section we will mainly use <code>scikit-learn</code>&rsquo;s <a href=https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html><code>make_regression</code></a> method.</p><p>For reproducibility, we will set a <code>random_state</code>.</p><p>We will create a dataset using <code>make_regression</code>&rsquo;s random linear regression model with input features $x=(f_1,f_2,f_3,f_4)$ and an output $y$.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>pandas</span> <span style=font-weight:700>as</span> <span style=color:#555>pd</span>
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.datasets</span> <span style=font-weight:700>import</span> make_regression
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>scipy.stats</span> <span style=font-weight:700>import</span> linregress
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>N_FEATURES <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>N_TARGETS <span style=font-weight:700>=</span> <span style=color:#099>1</span>
</span></span><span style=display:flex><span>N_SAMPLES <span style=font-weight:700>=</span> <span style=color:#099>100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset <span style=font-weight:700>=</span> make_regression(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_targets<span style=font-weight:700>=</span>N_TARGETS,
</span></span><span style=display:flex><span>    bias<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    effective_rank<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    tail_strength<span style=font-weight:700>=</span><span style=color:#099>0.5</span>,
</span></span><span style=display:flex><span>    noise<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    coef<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#999>print</span>(dataset[<span style=color:#099>0</span>][:<span style=color:#099>10</span>])
</span></span><span style=display:flex><span><span style=color:#999>print</span>(dataset[<span style=color:#099>1</span>][:<span style=color:#099>10</span>])
</span></span></code></pre></div><pre><code>[[ 0.87305874 -1.63096187  0.52538404 -0.19035824]
 [ 1.00698671  0.79834941 -0.04057655 -0.31358605]
 [-0.61464273  1.65110321  0.75791487 -0.0039844 ]
 [-1.08536678  1.82337823  0.4612592  -1.72325306]
 [-1.67774847 -0.54401341  0.86347869 -0.30250463]
 [-0.02427254  0.75537599 -0.04644972 -0.85153564]
 [-0.48085576  0.82100952 -0.9390196  -0.25870492]
 [-0.66772841 -2.46244005 -0.19855095 -1.85756579]
 [-0.29810663 -0.02239635  0.25363492 -1.22688366]
 [ 1.48146924  0.38269965 -1.18208819 -1.31062148]]
[  20.00449025  -30.41054677   52.65371365 -119.26376184   33.78805456
  -78.12189078  -88.41673748 -177.21674804  -90.13920313 -197.90799195]
</code></pre><p>Let&rsquo;s turn this dataset into a Pandas <code>DataFrame</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data<span style=font-weight:700>=</span>dataset[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> dataset[<span style=color:#099>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>f1</th><th>f2</th><th>f3</th><th>f4</th><th>y</th></tr></thead><tbody><tr><th>0</th><td>0.873</td><td>-1.631</td><td>0.525</td><td>-0.190</td><td>20.004</td></tr><tr><th>1</th><td>1.007</td><td>0.798</td><td>-0.041</td><td>-0.314</td><td>-30.411</td></tr><tr><th>2</th><td>-0.615</td><td>1.651</td><td>0.758</td><td>-0.004</td><td>52.654</td></tr><tr><th>3</th><td>-1.085</td><td>1.823</td><td>0.461</td><td>-1.723</td><td>-119.264</td></tr><tr><th>4</th><td>-1.678</td><td>-0.544</td><td>0.863</td><td>-0.303</td><td>33.788</td></tr></tbody></table></div><p>Let&rsquo;s plot the data:</p><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-5-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-5-output-1.png"></figure><h3 id=changing-the-gaussian-noise-level x-intersect="currentHeading = '#changing-the-gaussian-noise-level'">Changing the Gaussian noise level</h3><p>The <code>noise</code> parameter in <code>make_regression</code> allows to adjust the scale of the data&rsquo;s gaussian centered noise.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dataset <span style=font-weight:700>=</span> make_regression(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_targets<span style=font-weight:700>=</span>N_TARGETS,
</span></span><span style=display:flex><span>    bias<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    effective_rank<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    tail_strength<span style=font-weight:700>=</span><span style=color:#099>0.5</span>,
</span></span><span style=display:flex><span>    noise<span style=font-weight:700>=</span><span style=color:#099>2.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    coef<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data<span style=font-weight:700>=</span>dataset[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> dataset[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-7-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-7-output-1.png"></figure><h3 id=visualising-increasing-noise x-intersect="currentHeading = '#visualising-increasing-noise'">Visualising increasing noise</h3><p>Let&rsquo;s increase the noise by $10^i$, for $i=1, 2, 3$ and see what the data looks like.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>zeros((N_SAMPLES, <span style=color:#099>1</span>)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>create_noisy_data</span>(noise):
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> make_regression(
</span></span><span style=display:flex><span>        n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>        n_features<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        n_informative<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        n_targets<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        bias<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>        effective_rank<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>        tail_strength<span style=font-weight:700>=</span><span style=color:#099>0.5</span>,
</span></span><span style=display:flex><span>        noise<span style=font-weight:700>=</span>noise,
</span></span><span style=display:flex><span>        shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>        coef<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>        random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>3</span>):
</span></span><span style=display:flex><span>    data <span style=font-weight:700>=</span> create_noisy_data(<span style=color:#099>10</span> <span style=font-weight:700>**</span> i)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    df[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>0</span>]
</span></span><span style=display:flex><span>    df[<span style=color:#b84>f</span><span style=color:#b84>&#34;y</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-9-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-9-output-1.png"></figure><h2 id=classification-data x-intersect="currentHeading = '#classification-data'">Classification data</h2><p>To generate data for classification we will use the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html><sub>make_classification</sub></a> method.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.datasets</span> <span style=font-weight:700>import</span> make_classification
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>N <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>4</span>,
</span></span><span style=display:flex><span>    n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>    weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    flip_y<span style=font-weight:700>=</span><span style=color:#099>0.01</span>,
</span></span><span style=display:flex><span>    class_sep<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span><span style=display:flex><span>df<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>f1</th><th>f2</th><th>f3</th><th>f4</th><th>y</th></tr></thead><tbody><tr><th>0</th><td>-3.216</td><td>-0.416</td><td>-1.295</td><td>-1.882</td><td>0</td></tr><tr><th>1</th><td>-1.426</td><td>-1.257</td><td>-1.734</td><td>-1.804</td><td>0</td></tr><tr><th>2</th><td>2.798</td><td>-3.010</td><td>-1.085</td><td>-3.134</td><td>1</td></tr><tr><th>3</th><td>0.633</td><td>2.502</td><td>-1.553</td><td>1.625</td><td>1</td></tr><tr><th>4</th><td>1.494</td><td>0.912</td><td>-1.887</td><td>-1.457</td><td>1</td></tr></tbody></table></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-11-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-11-output-1.png"></figure><h3 id=cluster-separation x-intersect="currentHeading = '#cluster-separation'">Cluster separation</h3><p>According to the docs<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, <code>class_sep</code> is the factor multiplying the hypercube size.</p><p>Larger values spread out the clusters/classes and make the classification task easier.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N_FEATURES <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>4</span>,
</span></span><span style=display:flex><span>    n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>    weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    flip_y<span style=font-weight:700>=</span><span style=color:#099>0.01</span>,
</span></span><span style=display:flex><span>    class_sep<span style=font-weight:700>=</span><span style=color:#099>3.0</span>,
</span></span><span style=display:flex><span>    hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-13-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-13-output-1.png"></figure><p>We can make the cluster separability more difficult, by decreasing the value of <code>class_sep</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N_FEATURES <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>4</span>,
</span></span><span style=display:flex><span>    n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>    weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    flip_y<span style=font-weight:700>=</span><span style=color:#099>0.01</span>,
</span></span><span style=display:flex><span>    class_sep<span style=font-weight:700>=</span><span style=color:#099>0.5</span>,
</span></span><span style=display:flex><span>    hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-15-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-15-output-1.png"></figure><h3 id=noise-level x-intersect="currentHeading = '#noise-level'">Noise level</h3><p>According to the documentation<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, <code>flip_y</code> is the fraction of samples whose class is assigned randomly.</p><p>Larger values introduce noise in the labels and make the classification task harder.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N_FEATURES <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>6</span>):
</span></span><span style=display:flex><span>    data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>        n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>        n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>        n_informative<span style=font-weight:700>=</span><span style=color:#099>4</span>,
</span></span><span style=display:flex><span>        n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>        n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>        n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>        n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>        flip_y<span style=font-weight:700>=</span><span style=color:#099>0.1</span> <span style=font-weight:700>*</span> i,
</span></span><span style=display:flex><span>        class_sep<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>        hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>        shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>        scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>        shuffle<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>        random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>    df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>subplot(<span style=color:#099>2</span>, <span style=color:#099>3</span>, i <span style=font-weight:700>+</span> <span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>title(<span style=color:#b84>f</span><span style=color:#b84>&#34;$flip_y=</span><span style=color:#b84>{</span><span style=color:#999>round</span>(<span style=color:#099>0.1</span><span style=font-weight:700>*</span>i,<span style=color:#099>2</span>)<span style=color:#b84>}</span><span style=color:#b84>$&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>scatter(
</span></span><span style=display:flex><span>        df[<span style=color:#b84>&#34;f1&#34;</span>],
</span></span><span style=display:flex><span>        df[<span style=color:#b84>&#34;f2&#34;</span>],
</span></span><span style=display:flex><span>        s<span style=font-weight:700>=</span><span style=color:#099>50</span>,
</span></span><span style=display:flex><span>        c<span style=font-weight:700>=</span>df[<span style=color:#b84>&#34;y&#34;</span>],
</span></span><span style=display:flex><span>        cmap<span style=font-weight:700>=</span><span style=color:#b84>&#39;gray&#39;</span>,
</span></span><span style=display:flex><span>        edgecolor<span style=font-weight:700>=</span><span style=color:#b84>&#39;gray&#39;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>xlabel(<span style=color:#b84>f</span><span style=color:#b84>&#34;$</span><span style=color:#b84>{</span>var1[<span style=color:#099>0</span>]<span style=color:#b84>}</span><span style=color:#b84>_</span><span style=color:#b84>{</span>var1[<span style=color:#099>1</span>]<span style=color:#b84>}</span><span style=color:#b84>$&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>ylabel(<span style=color:#b84>f</span><span style=color:#b84>&#34;$</span><span style=color:#b84>{</span>var2[<span style=color:#099>0</span>]<span style=color:#b84>}</span><span style=color:#b84>_</span><span style=color:#b84>{</span>var2[<span style=color:#099>1</span>]<span style=color:#b84>}</span><span style=color:#b84>$&#34;</span>)
</span></span><span style=display:flex><span>    ax <span style=font-weight:700>=</span> plt<span style=font-weight:700>.</span>gca()
</span></span><span style=display:flex><span>    ax<span style=font-weight:700>.</span>set_facecolor((<span style=color:#099>247.0</span><span style=font-weight:700>/</span><span style=color:#099>255.0</span>, <span style=color:#099>239.0</span><span style=font-weight:700>/</span><span style=color:#099>255.0</span>, <span style=color:#099>217.0</span><span style=font-weight:700>/</span><span style=color:#099>255.0</span>))
</span></span><span style=display:flex><span>    plt<span style=font-weight:700>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=font-weight:700>.</span>tight_layout(pad<span style=font-weight:700>=</span><span style=color:#099>3.0</span>)
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-16-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-16-output-1.png"></figure><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data<span style=font-weight:700>=</span>np<span style=font-weight:700>.</span>zeros((N_SAMPLES, <span style=color:#099>1</span>)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>3</span>):
</span></span><span style=display:flex><span>    data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>        n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>        n_features<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>        n_informative<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>        n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>        n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>        n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>        n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>        weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>        flip_y<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>        class_sep<span style=font-weight:700>=</span>i <span style=font-weight:700>+</span> <span style=color:#099>0.5</span>,
</span></span><span style=display:flex><span>        hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>        shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>        scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>        shuffle<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>        random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    df[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>1&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>0</span>][:, <span style=color:#099>0</span>]
</span></span><span style=display:flex><span>    df[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>2&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>0</span>][:, <span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    df[<span style=color:#b84>f</span><span style=color:#b84>&#34;t</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-18-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-18-output-1.png"></figure><p>It is noteworthy that many paremeters in <code>scikit-learn</code> for synthetic data generation allow inputs per feature or cluster.
To do so, we simple pass the parameter value as an array.
For instance, to</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_classification(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N,
</span></span><span style=display:flex><span>    n_informative<span style=font-weight:700>=</span><span style=color:#099>4</span>,
</span></span><span style=display:flex><span>    n_redundant<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_repeated<span style=font-weight:700>=</span><span style=color:#099>0</span>,
</span></span><span style=display:flex><span>    n_classes<span style=font-weight:700>=</span><span style=color:#099>2</span>,
</span></span><span style=display:flex><span>    n_clusters_per_class<span style=font-weight:700>=</span><span style=color:#099>1</span>,
</span></span><span style=display:flex><span>    weights<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>    flip_y<span style=font-weight:700>=</span><span style=color:#099>0.01</span>,
</span></span><span style=display:flex><span>    class_sep<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    hypercube<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    shift<span style=font-weight:700>=</span><span style=color:#099>0.0</span>,
</span></span><span style=display:flex><span>    scale<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span>random_state,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><h2 id=separability x-intersect="currentHeading = '#separability'">Separability</h2><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.datasets</span> <span style=font-weight:700>import</span> make_blobs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>N_FEATURE <span style=font-weight:700>=</span> <span style=color:#099>4</span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_blobs(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span><span style=color:#099>60</span>,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURE,
</span></span><span style=display:flex><span>    centers<span style=font-weight:700>=</span><span style=color:#099>3</span>,
</span></span><span style=display:flex><span>    cluster_std<span style=font-weight:700>=</span><span style=color:#099>1.0</span>,
</span></span><span style=display:flex><span>    center_box<span style=font-weight:700>=</span>(<span style=font-weight:700>-</span><span style=color:#099>5.0</span>, <span style=color:#099>5.0</span>),
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURE)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-21-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-21-output-1.png"></figure><p>To make a cluster more separable we can change <code>cluster_std</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=font-weight:700>=</span> make_blobs(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span><span style=color:#099>60</span>,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    centers<span style=font-weight:700>=</span><span style=color:#099>3</span>,
</span></span><span style=display:flex><span>    cluster_std<span style=font-weight:700>=</span><span style=color:#099>0.3</span>,
</span></span><span style=display:flex><span>    center_box<span style=font-weight:700>=</span>(<span style=font-weight:700>-</span><span style=color:#099>5.0</span>, <span style=color:#099>5.0</span>),
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-23-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-23-output-1.png"></figure><p>By decreasing <code>cluster_std</code> we make them less separable.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=font-weight:700>=</span> make_blobs(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span><span style=color:#099>60</span>,
</span></span><span style=display:flex><span>    n_features<span style=font-weight:700>=</span>N_FEATURES,
</span></span><span style=display:flex><span>    centers<span style=font-weight:700>=</span><span style=color:#099>3</span>,
</span></span><span style=display:flex><span>    cluster_std<span style=font-weight:700>=</span><span style=color:#099>2.5</span>,
</span></span><span style=display:flex><span>    center_box<span style=font-weight:700>=</span>(<span style=font-weight:700>-</span><span style=color:#099>5.0</span>, <span style=color:#099>5.0</span>),
</span></span><span style=display:flex><span>    shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>,
</span></span><span style=display:flex><span>    random_state<span style=font-weight:700>=</span><span style=font-weight:700>None</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(N_FEATURES)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-25-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-25-output-1.png"></figure><h3 id=anisotropic-data x-intersect="currentHeading = '#anisotropic-data'">Anisotropic data</h3><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=font-weight:700>=</span> make_blobs(n_samples<span style=font-weight:700>=</span><span style=color:#099>50</span>, n_features<span style=font-weight:700>=</span><span style=color:#099>2</span>, centers<span style=font-weight:700>=</span><span style=color:#099>3</span>, cluster_std<span style=font-weight:700>=</span><span style=color:#099>1.5</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>transformation <span style=font-weight:700>=</span> [<span style=color:#099>0.5</span>, <span style=font-weight:700>-</span><span style=color:#099>0.5</span>], [<span style=font-weight:700>-</span><span style=color:#099>0.4</span>, <span style=color:#099>0.8</span>]()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data_0 <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>dot(data[<span style=color:#099>0</span>], transformation)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data_0, columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>1</span>, <span style=color:#099>3</span>)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-29-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-29-output-1.png"></figure><h2 id=concentric-clusters x-intersect="currentHeading = '#concentric-clusters'">Concentric clusters</h2><p>Sometimes we might be interested in creating a non-separable cluster.
The simples way is to create concentric clusters with the <code>make_circles</code> method.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.datasets</span> <span style=font-weight:700>import</span> make_circles
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_circles(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES, shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>, noise<span style=font-weight:700>=</span><span style=font-weight:700>None</span>, random_state<span style=font-weight:700>=</span>random_state, factor<span style=font-weight:700>=</span><span style=color:#099>0.6</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>2</span>)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-31-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-31-output-1.png"></figure><h3 id=adding-noise x-intersect="currentHeading = '#adding-noise'">Adding noise</h3><p>The <code>noise</code> parameter allows to create a concentric noisy dataset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=font-weight:700>=</span> make_circles(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES, shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>, noise<span style=font-weight:700>=</span><span style=color:#099>0.15</span>, random_state<span style=font-weight:700>=</span>random_state, factor<span style=font-weight:700>=</span><span style=color:#099>0.6</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>2</span>)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-33-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-33-output-1.png"></figure><h2 id=moon-clusters x-intersect="currentHeading = '#moon-clusters'">Moon clusters</h2><p>A shape that can be useful to other methods (such as <a href=/counterfactuals.html>Counterfactuals</a>, for instance) is the one generated by the <code>make_moons</code> method.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.datasets</span> <span style=font-weight:700>import</span> make_moons
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> make_moons(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES, shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>, noise<span style=font-weight:700>=</span><span style=font-weight:700>None</span>, random_state<span style=font-weight:700>=</span>random_state
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>2</span>)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-35-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-35-output-1.png"></figure><h3 id=adding-noise-1 x-intersect="currentHeading = '#adding-noise-1'">Adding noise</h3><p>As usual, the <code>noise</code> parameter allows to control the noise.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=font-weight:700>=</span> make_moons(
</span></span><span style=display:flex><span>    n_samples<span style=font-weight:700>=</span>N_SAMPLES, shuffle<span style=font-weight:700>=</span><span style=font-weight:700>True</span>, noise<span style=font-weight:700>=</span><span style=color:#099>0.1</span>, random_state<span style=font-weight:700>=</span>random_state
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>DataFrame(data[<span style=color:#099>0</span>], columns<span style=font-weight:700>=</span>[<span style=color:#b84>f</span><span style=color:#b84>&#34;f</span><span style=color:#b84>{</span>i<span style=font-weight:700>+</span><span style=color:#099>1</span><span style=color:#b84>}</span><span style=color:#b84>&#34;</span> <span style=font-weight:700>for</span> i <span style=font-weight:700>in</span> <span style=color:#999>range</span>(<span style=color:#099>2</span>)])
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;y&#34;</span>] <span style=font-weight:700>=</span> data[<span style=color:#099>1</span>]
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-37-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-37-output-1.png"></figure><h2 id=time-series-data x-intersect="currentHeading = '#time-series-data'">Time-series data</h2><h3 id=random-walk x-intersect="currentHeading = '#random-walk'">Random walk</h3><p>See [<a href=#random-walk>Random walk</a>].</p><h3 id=simple-periodic x-intersect="currentHeading = '#simple-periodic'">Simple periodic</h3><h4 id=no-trend x-intersect="currentHeading = '#no-trend'">No trend</h4><p>Generate a simple HMM with a sine state and gaussian observations:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>generate_sine</span>(period, n):
</span></span><span style=display:flex><span>    cycles <span style=font-weight:700>=</span> n <span style=font-weight:700>/</span> period
</span></span><span style=display:flex><span>    length <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>pi <span style=font-weight:700>*</span> <span style=color:#099>2</span> <span style=font-weight:700>*</span> cycles
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> np<span style=font-weight:700>.</span>sin(np<span style=font-weight:700>.</span>arange(<span style=color:#099>0</span>, length, length <span style=font-weight:700>/</span> n))
</span></span></code></pre></div><p>We will now get a set of $n=1000$ observations with a $p=10$ period</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N<span style=font-weight:700>=</span><span style=color:#099>1000</span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> generate_sine(<span style=color:#099>10</span>, N) <span style=font-weight:700>*</span> np<span style=font-weight:700>.</span>random<span style=font-weight:700>.</span>uniform(<span style=color:#099>10</span>, size<span style=font-weight:700>=</span>N)
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-40-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-40-output-1.png"></figure><h4 id=trend x-intersect="currentHeading = '#trend'">Trend</h4><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N<span style=font-weight:700>=</span><span style=color:#099>1000</span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> (generate_sine(<span style=color:#099>10</span>, N) <span style=font-weight:700>*</span> np<span style=font-weight:700>.</span>random<span style=font-weight:700>.</span>uniform(<span style=color:#099>10</span>, size<span style=font-weight:700>=</span>N)) <span style=font-weight:700>+</span> np<span style=font-weight:700>.</span>arange(N)<span style=font-weight:700>/</span><span style=color:#099>200.0</span>
</span></span></code></pre></div><figure><img src=/site/Machine%20learning/Synthetic%20Data%20Generation_files/figure-gfm/cell-42-output-1.png alt="Synthetic Data Generation_files/figure-gfm/cell-42-output-1.png"></figure><h3 id=univariate-data x-intersect="currentHeading = '#univariate-data'">Univariate data</h3><p>Using the <code>streamad</code> library:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>streamad.util.dataset</span> <span style=font-weight:700>import</span> CustomDS
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>streamad.util</span> <span style=font-weight:700>import</span> StreamGenerator, plot
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ds <span style=font-weight:700>=</span> CustomDS(<span style=color:#b84>&#34;../../data/streamad/uniDS.csv&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>stream <span style=font-weight:700>=</span> StreamGenerator(ds<span style=font-weight:700>.</span>data)
</span></span></code></pre></div><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html>https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html>https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#generating-synthetic-data>Generating synthetic data</a></li><li><a href=#regression-data>Regression data</a><ul><li><a href=#changing-the-gaussian-noise-level>Changing the Gaussian noise level</a></li><li><a href=#visualising-increasing-noise>Visualising increasing noise</a></li></ul></li><li><a href=#classification-data>Classification data</a><ul><li><a href=#cluster-separation>Cluster separation</a></li><li><a href=#noise-level>Noise level</a></li></ul></li><li><a href=#separability>Separability</a><ul><li><a href=#anisotropic-data>Anisotropic data</a></li></ul></li><li><a href=#concentric-clusters>Concentric clusters</a><ul><li><a href=#adding-noise>Adding noise</a></li></ul></li><li><a href=#moon-clusters>Moon clusters</a><ul><li><a href=#adding-noise-1>Adding noise</a></li></ul></li><li><a href=#time-series-data>Time-series data</a><ul><li><a href=#random-walk>Random walk</a></li><li><a href=#simple-periodic>Simple periodic</a></li><li><a href=#univariate-data>Univariate data</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2023 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/css/fa.min.css><script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/mark.min.js></script>
<script src=/js/main.js></script>
<script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>