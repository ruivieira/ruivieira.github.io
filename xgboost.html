<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script src=https://unpkg.com/@alpinejs/intersect@3.x.x/dist/cdn.min.js></script>
<script src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script>
<script type=module src=/js/deeplinks/deeplinks.js></script>
<link rel=preload href=/lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/firacode/FiraCode-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/fonts/prociono/Prociono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=/css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>XGBoost · Rui Vieira</title><link rel=canonical href=/xgboost.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="XGBoost"><meta property="og:description" content="IntroductionXGBoost1 is a popular regularizing gradient boosting framework.
InstallationIn most systems, installing XGBoost can be done simply by using pip
$ pip install xgboost ExampleTraining XGBoost with the credit-bias dataset.
import pandas as pd data = pd.read_csv(&#34;../data/credit-bias-train.zip&#34;) data.head() NewCreditCustomer Amount Interest LoanDuration Education NrOfDependants EmploymentDurationCurrentEmployer IncomeFromPrincipalEmployer IncomeFromPension IncomeFromFamilyAllowance ... Mortgage Other Owner Owner_with_encumbrance Tenant Entrepreneur Fully Partially Retiree Self_employed 0 False 2125.0 20.97 60 4.0 0.0 6.0 0.0 301.0 0.0 ."><meta property="og:type" content="article"><meta property="og:url" content="/xgboost.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2023-05-28T11:45:56+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="XGBoost"><meta name=twitter:description content="IntroductionXGBoost1 is a popular regularizing gradient boosting framework.
InstallationIn most systems, installing XGBoost can be done simply by using pip
$ pip install xgboost ExampleTraining XGBoost with the credit-bias dataset.
import pandas as pd data = pd.read_csv(&#34;../data/credit-bias-train.zip&#34;) data.head() NewCreditCustomer Amount Interest LoanDuration Education NrOfDependants EmploymentDurationCurrentEmployer IncomeFromPrincipalEmployer IncomeFromPension IncomeFromFamilyAllowance ... Mortgage Other Owner Owner_with_encumbrance Tenant Entrepreneur Fully Partially Retiree Self_employed 0 False 2125.0 20.97 60 4.0 0.0 6.0 0.0 301.0 0.0 ."><link rel=stylesheet href=/css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=images/favicon.ico></head><body class="max-width mx-auto px3 ltr" x-data="{currentHeading: undefined}"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></span><br><div id=share style=display:none></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#introduction :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#introduction' }">Introduction</a></li><li><a href=#installation :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#installation' }">Installation</a></li><li><a href=#example :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#example' }">Example</a></li><li><a href=#hyperparameter-estimation :class="{'toc-h3':true, 'toc-highlight': currentHeading == '#hyperparameter-estimation' }">Hyperparameter estimation</a></li><li><a href=#objective-function :class="{'toc-h4':true, 'toc-highlight': currentHeading == '#objective-function' }">Objective function</a></li><li><a href=#weight-balance :class="{'toc-h4':true, 'toc-highlight': currentHeading == '#weight-balance' }">Weight balance</a></li><li><a href=#visualisation :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#visualisation' }">Visualisation</a></li><li><a href=#roc-and-auc :class="{'toc-h2':true, 'toc-highlight': currentHeading == '#roc-and-auc' }">ROC and AUC</a></li></ul></nav></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">XGBoost</h1><div class=meta><div class=postdate>Updated <time datetime="2023-05-28 11:45:56 +0100 BST" itemprop=datePublished>2023-05-28</time>
<span class=commit-hash>(<a href=/log/index.html#1454e0a>1454e0a</a>)</span></div></div></header><div class=content itemprop=articleBody><h2 id=introduction x-intersect="currentHeading = '#introduction'">Introduction</h2><p><code>XGBoost</code><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> is a popular regularizing gradient boosting framework.</p><h2 id=installation x-intersect="currentHeading = '#installation'">Installation</h2><p>In most systems, installing <code>XGBoost</code> can be done simply by using <code>pip</code></p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ pip install xgboost
</span></span></code></pre></div><h2 id=example x-intersect="currentHeading = '#example'">Example</h2><p>Training XGBoost with the credit-bias dataset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>pandas</span> <span style=font-weight:700>as</span> <span style=color:#555>pd</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>read_csv(<span style=color:#b84>&#34;../data/credit-bias-train.zip&#34;</span>)
</span></span><span style=display:flex><span>data<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>NewCreditCustomer</th><th>Amount</th><th>Interest</th><th>LoanDuration</th><th>Education</th><th>NrOfDependants</th><th>EmploymentDurationCurrentEmployer</th><th>IncomeFromPrincipalEmployer</th><th>IncomeFromPension</th><th>IncomeFromFamilyAllowance</th><th>...</th><th>Mortgage</th><th>Other</th><th>Owner</th><th>Owner_with_encumbrance</th><th>Tenant</th><th>Entrepreneur</th><th>Fully</th><th>Partially</th><th>Retiree</th><th>Self_employed</th></tr></thead><tbody><tr><th>0</th><td>False</td><td>2125.0</td><td>20.97</td><td>60</td><td>4.0</td><td>0.0</td><td>6.0</td><td>0.0</td><td>301.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><th>1</th><td>False</td><td>3000.0</td><td>17.12</td><td>60</td><td>5.0</td><td>0.0</td><td>6.0</td><td>900.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>True</td><td>9100.0</td><td>13.67</td><td>60</td><td>4.0</td><td>1.0</td><td>3.0</td><td>600.0</td><td>0.0</td><td>0.0</td><td>...</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>True</td><td>635.0</td><td>42.66</td><td>60</td><td>2.0</td><td>0.0</td><td>1.0</td><td>745.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>False</td><td>5000.0</td><td>24.52</td><td>60</td><td>4.0</td><td>1.0</td><td>5.0</td><td>1000.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><p>5 rows × 40 columns</p></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_df <span style=font-weight:700>=</span> data<span style=font-weight:700>.</span>drop(<span style=color:#b84>&#39;PaidLoan&#39;</span>, axis<span style=font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>y_df <span style=font-weight:700>=</span> data[<span style=color:#b84>&#39;PaidLoan&#39;</span>]
</span></span><span style=display:flex><span>y_df<span style=font-weight:700>.</span>describe()
</span></span></code></pre></div><pre><code>count     58003
unique        2
top        True
freq      29219
Name: PaidLoan, dtype: object
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.model_selection</span> <span style=font-weight:700>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_x, test_x, train_y, test_y <span style=font-weight:700>=</span> train_test_split(X_df, y_df, test_size<span style=font-weight:700>=</span><span style=color:#099>0.25</span>, random_state<span style=font-weight:700>=</span><span style=color:#099>42</span>)
</span></span></code></pre></div><h3 id=hyperparameter-estimation x-intersect="currentHeading = '#hyperparameter-estimation'">Hyperparameter estimation</h3><p>Runs a grid search to find the tuning parameters that maxisimise the area under the curve (AUC). <code>train_x</code> is the training data frame with loan details and <code>train_y</code> is the default target column for training.
The method returns the best parameters and corresponding AUC score.</p><p>The <code>objective</code> parameter<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> specifies the learning task and the corresponding learning objective. Possible values include:</p><h4 id=objective-function x-intersect="currentHeading = '#objective-function'">Objective function</h4><ul><li><code>reg:squarederror</code>, regression with squared loss.</li><li><code>reg:squaredlogerror</code>, regression with squared log loss</li><li><code>reg:logistic</code>, logistic regression</li><li><code>reg:pseudohubererror</code>, regression with Pseudo Huber loss, a twice differentiable alternative to absolute loss.</li><li><code>binary:logistic</code>, logistic regression for binary classification, output probability</li><li><code>binary:logitraw</code>, logistic regression for binary classification, output score before logistic transformation</li><li><code>binary:hinge</code>, <a href>hinge loss</a> for binary classification. This makes predictions of 0 or 1, rather than producing probabilities.</li><li><code>count:poisson</code>, poisson regression for count data, output mean of Poisson distribution</li><li><code>survival:cox</code>, Cox regression for right censored survival time data (negative values are considered right censored).</li><li><code>survival:aft</code>, Accelerated failure time model for censored survival time data. See Survival Analysis with Accelerated Failure Time for details.</li><li><code>aft_loss_distribution</code>, Probability Density Function used by survival:aft objective and aft-nloglik metric.</li><li><code>multi:softmax</code>, set XGBoost to do multiclass classification using the softmax objective, you also need to set <sub>num_class</sub> (number of classes)</li><li><code>multi:softprob</code>, same as softmax, but output a vector of <code>ndata * nclas</code>s, which can be further reshaped to <code>ndata * nclass</code> matrix. The result contains predicted probability of each data point belonging to each class.</li><li><code>rank:pairwise</code>, Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized</li><li><code>rank:ndcg</code>, Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized</li><li><code>rank:map</code>, Use LambdaMART to perform list-wise ranking where Mean Average Precision (MAP) is maximized</li><li><code>reg:gamma</code>, gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be gamma-distributed.</li><li><code>reg:tweedie</code>, Tweedie regression with log-link. It might be useful, <em>e.g.</em>, for modeling total loss in insurance, or for any outcome that might be Tweedie-distributed.</li></ul><h4 id=weight-balance x-intersect="currentHeading = '#weight-balance'">Weight balance</h4><p><code>scale_pos_weight</code> (default <code>1</code>) controls the balance of <em>positive</em> and <em>negative</em> weights, useful for unbalanced classes.
A typical value to consider is <code>sum(negative instances) / sum(positive instances)</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.model_selection</span> <span style=font-weight:700>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>xgboost.sklearn</span> <span style=font-weight:700>import</span> XGBClassifier
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>typing</span> <span style=font-weight:700>import</span> Tuple
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>find_best_xgboost_model</span>(train_x: pd<span style=font-weight:700>.</span>DataFrame, train_y: pd<span style=font-weight:700>.</span>Series) <span style=font-weight:700>-&gt;</span> Tuple[<span style=color:#999>dict</span>, <span style=color:#999>float</span>]:
</span></span><span style=display:flex><span>    scale_pos_weight <span style=font-weight:700>=</span> (<span style=color:#999>len</span>(train_y) <span style=font-weight:700>-</span> train_y<span style=font-weight:700>.</span>sum()) <span style=font-weight:700>/</span> train_y<span style=font-weight:700>.</span>sum()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    param_test <span style=font-weight:700>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#b84>&#39;max_depth&#39;</span>: [<span style=color:#099>1</span>, <span style=color:#099>2</span>, <span style=color:#099>4</span>, <span style=color:#099>8</span>],
</span></span><span style=display:flex><span>            <span style=color:#b84>&#39;learning_rate&#39;</span>: [<span style=color:#099>0.05</span>, <span style=color:#099>0.06</span>, <span style=color:#099>0.07</span>],
</span></span><span style=display:flex><span>            <span style=color:#b84>&#39;n_estimators&#39;</span>: [<span style=color:#099>10</span>, <span style=color:#099>50</span>, <span style=color:#099>100</span>]
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    gsearch <span style=font-weight:700>=</span> GridSearchCV(estimator<span style=font-weight:700>=</span>XGBClassifier(
</span></span><span style=display:flex><span>        use_label_encoder<span style=font-weight:700>=</span><span style=font-weight:700>False</span>,
</span></span><span style=display:flex><span>        objective<span style=font-weight:700>=</span><span style=color:#b84>&#39;binary:logistic&#39;</span>,
</span></span><span style=display:flex><span>        scale_pos_weight<span style=font-weight:700>=</span>scale_pos_weight,
</span></span><span style=display:flex><span>        tree_method <span style=font-weight:700>=</span> <span style=color:#b84>&#34;hist&#34;</span>,
</span></span><span style=display:flex><span>        seed<span style=font-weight:700>=</span><span style=color:#099>27</span>),
</span></span><span style=display:flex><span>        param_grid<span style=font-weight:700>=</span>param_test, scoring<span style=font-weight:700>=</span><span style=color:#b84>&#39;roc_auc&#39;</span>, n_jobs<span style=font-weight:700>=-</span><span style=color:#099>1</span>, cv<span style=font-weight:700>=</span><span style=color:#099>8</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    gsearch<span style=font-weight:700>.</span>fit(train_x, train_y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> gsearch<span style=font-weight:700>.</span>best_params_, gsearch<span style=font-weight:700>.</span>best_score_
</span></span><span style=display:flex><span>best_params, best_score <span style=font-weight:700>=</span> find_best_xgboost_model(train_x, train_y)
</span></span></code></pre></div><p>Using the xgboost model parameters, it predicts the probabilities of defaulting.</p><ul><li><code>best_params_</code>, best tuning parameters</li><li><code>train_x</code>, training dataframe with loan details</li><li><code>train_y</code>, default target column for training</li><li><code>test_x</code>, testing dataframe with loan details</li><li><code>test_y</code>, default target column for testing</li></ul><p>The result is a series of probabilities whether loan entry will default or not and corresponding model&rsquo;s AUC score</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.metrics</span> <span style=font-weight:700>import</span> roc_auc_score
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>xgboost_predict</span>(best_params_: <span style=color:#999>dict</span>, train_x: pd<span style=font-weight:700>.</span>DataFrame, train_y: pd<span style=font-weight:700>.</span>Series, test_x: pd<span style=font-weight:700>.</span>DataFrame,
</span></span><span style=display:flex><span>                    test_y: pd<span style=font-weight:700>.</span>Series) <span style=font-weight:700>-&gt;</span> Tuple[<span style=color:#999>list</span>, <span style=color:#999>float</span>]:
</span></span><span style=display:flex><span>    scale_pos_weight <span style=font-weight:700>=</span> (<span style=color:#999>len</span>(train_y) <span style=font-weight:700>-</span> train_y<span style=font-weight:700>.</span>sum()) <span style=font-weight:700>/</span> train_y<span style=font-weight:700>.</span>sum()
</span></span><span style=display:flex><span>    xgb_model <span style=font-weight:700>=</span> XGBClassifier(objective<span style=font-weight:700>=</span><span style=color:#b84>&#39;binary:logistic&#39;</span>,
</span></span><span style=display:flex><span>                              scale_pos_weight<span style=font-weight:700>=</span>scale_pos_weight,
</span></span><span style=display:flex><span>                              seed<span style=font-weight:700>=</span><span style=color:#099>27</span>,
</span></span><span style=display:flex><span>                              max_depth<span style=font-weight:700>=</span>best_params_[<span style=color:#b84>&#39;max_depth&#39;</span>],
</span></span><span style=display:flex><span>                              learning_rate<span style=font-weight:700>=</span>best_params_[<span style=color:#b84>&#39;learning_rate&#39;</span>],
</span></span><span style=display:flex><span>                              n_estimators<span style=font-weight:700>=</span>best_params_[<span style=color:#b84>&#39;n_estimators&#39;</span>]
</span></span><span style=display:flex><span>                              )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    xgb_model<span style=font-weight:700>.</span>fit(train_x, train_y)
</span></span><span style=display:flex><span>    predicted_probabilities_ <span style=font-weight:700>=</span> xgb_model<span style=font-weight:700>.</span>predict_proba(test_x)[:, <span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    auc_ <span style=font-weight:700>=</span> roc_auc_score(test_y, predicted_probabilities_)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> predicted_probabilities_, auc_
</span></span><span style=display:flex><span>predicted_probabilities, auc <span style=font-weight:700>=</span> xgboost_predict(best_params, train_x, train_y, test_x, test_y)
</span></span><span style=display:flex><span><span style=color:#999>print</span>(<span style=color:#b84>&#34;AUC: </span><span style=color:#b84>{}</span><span style=color:#b84>&#34;</span><span style=font-weight:700>.</span>format(auc))
</span></span></code></pre></div><pre><code>AUC: 0.7356799122465589
</code></pre><p>Filters the original loan dataframe to just include the loans from the test dataframe and then it adds the predicted probabilities.</p><ul><li><code>loans_df_</code>, original loan dataframe</li><li><code>test_index</code>, indices from the test dataframes</li><li><code>predicted_probabilities_</code>, the probabilities forecasted by the XGBoost model</li></ul><p>Returns the loans dataframe with predictions</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>prepare_test_with_predictions</span>(loans_df_: pd<span style=font-weight:700>.</span>DataFrame, test_index: pd<span style=font-weight:700>.</span>Index, predicted_probabilities_: np<span style=font-weight:700>.</span>array)\
</span></span><span style=display:flex><span>        <span style=font-weight:700>-&gt;</span>pd<span style=font-weight:700>.</span>DataFrame:
</span></span><span style=display:flex><span>    loan_test_df <span style=font-weight:700>=</span> loans_df_<span style=font-weight:700>.</span>loc[test_index]
</span></span><span style=display:flex><span>    loan_test_df[<span style=color:#b84>&#39;predicted_probabilities&#39;</span>] <span style=font-weight:700>=</span> predicted_probabilities_
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> loan_test_df
</span></span><span style=display:flex><span>loans_with_predictions_df <span style=font-weight:700>=</span> prepare_test_with_predictions(data, test_x<span style=font-weight:700>.</span>index, predicted_probabilities)
</span></span><span style=display:flex><span>loans_with_predictions_df<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>NewCreditCustomer</th><th>Amount</th><th>Interest</th><th>LoanDuration</th><th>Education</th><th>NrOfDependants</th><th>EmploymentDurationCurrentEmployer</th><th>IncomeFromPrincipalEmployer</th><th>IncomeFromPension</th><th>IncomeFromFamilyAllowance</th><th>...</th><th>Other</th><th>Owner</th><th>Owner_with_encumbrance</th><th>Tenant</th><th>Entrepreneur</th><th>Fully</th><th>Partially</th><th>Retiree</th><th>Self_employed</th><th>predicted_probabilities</th></tr></thead><tbody><tr><th>30299</th><td>False</td><td>530.0</td><td>10.68</td><td>36</td><td>4.0</td><td>NaN</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.641520</td></tr><tr><th>34126</th><td>False</td><td>530.0</td><td>21.57</td><td>24</td><td>4.0</td><td>NaN</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.770486</td></tr><tr><th>11200</th><td>False</td><td>2300.0</td><td>15.62</td><td>36</td><td>4.0</td><td>0.0</td><td>6.0</td><td>1159.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.748680</td></tr><tr><th>25133</th><td>True</td><td>530.0</td><td>27.36</td><td>36</td><td>4.0</td><td>NaN</td><td>6.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.469619</td></tr><tr><th>42758</th><td>True</td><td>4250.0</td><td>18.94</td><td>60</td><td>4.0</td><td>NaN</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.527547</td></tr></tbody></table><p>5 rows × 41 columns</p></div><h2 id=visualisation x-intersect="currentHeading = '#visualisation'">Visualisation</h2><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>seaborn</span> <span style=font-weight:700>as</span> <span style=color:#555>sns</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sns<span style=font-weight:700>.</span>histplot(loans_with_predictions_df[<span style=color:#b84>&#39;predicted_probabilities&#39;</span>], stat<span style=font-weight:700>=</span><span style=color:#b84>&#39;density&#39;</span>)
</span></span></code></pre></div><pre><code>&lt;AxesSubplot:xlabel='predicted_probabilities', ylabel='Density'&gt;
</code></pre><p><img src=XGBoost_files/figure-gfm/cell-8-output-2.png alt loading=lazy></p><h2 id=roc-and-auc x-intersect="currentHeading = '#roc-and-auc'">ROC and AUC</h2><p>Based on actuals and predicted values<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, it calculates their false positive rate (fpr), the true positive rate (tpr). It also returns the corresponding thresholds used as well as the value for the area under the curve.</p><p>actuals, series of actual values indicating whether the loan defaulted or not
predicted_probabilities, series of predicted probabilities of the loan defaulting
Return a unique series of false and true positive rates with corresponding series of thresholds and value for total area under the curve.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.metrics</span> <span style=font-weight:700>import</span> roc_curve, auc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>def</span> <span style=color:#900;font-weight:700>get_roc_auc_data</span>(actuals: pd<span style=font-weight:700>.</span>Series, predicted_probabilities: pd<span style=font-weight:700>.</span>Series) <span style=font-weight:700>-&gt;</span> Tuple[np<span style=font-weight:700>.</span>array, np<span style=font-weight:700>.</span>array, np<span style=font-weight:700>.</span>array, <span style=color:#999>float</span>]:
</span></span><span style=display:flex><span>    fpr, tpr, thresholds <span style=font-weight:700>=</span> roc_curve(actuals, predicted_probabilities, pos_label<span style=font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    auc_score <span style=font-weight:700>=</span> auc(fpr, tpr)
</span></span><span style=display:flex><span>    <span style=font-weight:700>return</span> fpr, tpr, thresholds, auc_score
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fpr, tpr, thresholds, auc_score <span style=font-weight:700>=</span> get_roc_auc_data(loans_with_predictions_df[<span style=color:#b84>&#39;PaidLoan&#39;</span>], loans_with_predictions_df[<span style=color:#b84>&#39;predicted_probabilities&#39;</span>])
</span></span><span style=display:flex><span>sns<span style=font-weight:700>.</span>histplot(fpr)
</span></span></code></pre></div><pre><code>&lt;AxesSubplot:ylabel='Count'&gt;
</code></pre><p><img src=XGBoost_files/figure-gfm/cell-9-output-2.png alt loading=lazy></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://github.com/dmlc/xgboost>https://github.com/dmlc/xgboost</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters>https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>See <a href=/roc.html>ROC</a>.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#installation>Installation</a></li><li><a href=#example>Example</a><ul><li><a href=#hyperparameter-estimation>Hyperparameter estimation</a></li></ul></li><li><a href=#visualisation>Visualisation</a></li><li><a href=#roc-and-auc>ROC and AUC</a></li></ul></nav></div><div id=share-footer style=display:none></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2023 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/map/>All pages</a></li><li><a href=/search.html>Search</a></li><li><a href=/draw/>Drawings</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/css/fa.min.css><script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/mark.min.js></script>
<script src=/js/main.js></script>
<script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>